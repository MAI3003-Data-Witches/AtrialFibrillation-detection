{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<a href=\"https://colab.research.google.com/github/MAI3003-Data-Witches/Data-Witches_Project2/blob/main/MAI3003_DataWitches_Assignment02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<a href=\"https://colab.research.google.com/github/MAI3003-Data-Witches/Data-Witches_Project2/blob/main/MAI3003_DataWitches_Assignment02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Data Witches**"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| **Name**         | **Student ID** |\n",
    "|------------------|----------------|\n",
    "| Claessen, VVHJAE | i6339543       |\n",
    "| Ovsiannikova, AM | i6365923       |\n",
    "| Pubben, J        | i6276134       |\n",
    "| Roca Cugat, M    | i6351071       |\n",
    "| Záboj, J         | i6337952       |"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Logbook**"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Changes**\n",
    "Also see Git Commit History.\n",
    "\n",
    "| **Version** | **Changes**                   | **Date** |\n",
    "|-------------|-------------------------------|----------|\n",
    "| v0.0        | Dataset loaded, EDA, cleaning | 18-11-25 |\n",
    "| v1.1        | ***                           | XX-11-25 |\n",
    "| v0.2        | ***                           | XX-11-25 |\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Methods\n",
    "\n",
    "Let's ensure we all use the same names for all components.  \n",
    "\n",
    "| **Variable**                 | **Name**                                      |\n",
    "|------------------------------|-----------------------------------------------|\n",
    "| Raw ECG dataframe            | df                                            |\n",
    "| Label dataframe              | df_labels                                     |\n",
    "| HRV features (train)         | hrv_train                                     |\n",
    "| HRV features (test)          | hrv_test                                      |\n",
    "| HRV extraction type          | FULL (nk.hrv — time + freq + nonlinear + RSA) |\n",
    "| Clean HRV dataframe (train)  | hrv_train_clean                               |\n",
    "| Clean HRV dataframe (test)   | hrv_test_clean                                |\n",
    "| HRV + labels (train)         | hrv_train_with_labels                         |\n",
    "| Winsorized HRV column        | HRV_MedianNN_winsor                           |\n",
    "| Model feature matrix (train) | X_train                                       |\n",
    "| Model feature matrix (test)  | X_test                                        |\n",
    "| Model target vector (train)  | y_train                                       |\n",
    "| Model target vector (test)   | y_test                                        |\n",
    "\n",
    "\n",
    "| **Function**              | **Description**                                | **Arguments**                                |\n",
    "|---------------------------|------------------------------------------------|----------------------------------------------|\n",
    "| corr_plot_hrv()           | Correlation plot for HRV features              | df, cols=None                                |\n",
    "| distplots_hrv()           | Distribution plots (hist + KDE)                | df, cols=None                                |\n",
    "| boxplots_hrv()            | Boxplots for selected HRV variables            | df, cols                                     |\n",
    "| check_missing_hrv()       | Missingness summary                            | df                                           |\n",
    "| identify_outliers()       | IQR-based outlier detection                    | df, column_name, threshold=1.5               |\n",
    "| model_evaluation()        | Confusion matrix + classification report       | model                                        |\n",
    "| model_desc()              | Accuracy, CV, ROC-AUC, model performance       | model                                        |\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preface"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Packages imports"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#!pip install -r requirements.txt",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os.path\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "from colorama import Fore, Back, Style\n",
    "from joblib.testing import xfail\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "from scipy.signal import welch\n",
    "from sklearn import tree\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, f1_score, \\\n",
    "    precision_score, recall_score, roc_auc_score, roc_curve, RocCurveDisplay, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sympy import false\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Options settings"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(3003)\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "DATA_PRESENT = os.path.isfile(\"data/Physionet2017Training.tar.xz\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset download"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if not DATA_PRESENT:\n",
    "    !mkdir data\n",
    "    !wget https://github.com/MAI3003-Data-Witches/Data-Witches_Project2/raw/refs/heads/main/data/Physionet2017Training.tar.xz -O data/Physionet2017Training.tar.xz\n",
    "    !tar -xf data/Physionet2017Training.tar.xz -C data\n",
    "else:\n",
    "    print(\"You already have the dataset downloaded, skipping\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('data/Physionet2017TrainingData.csv', header=None,\n",
    "                 index_col=False) * 1000  # Load the dataset already in mV\n",
    "#TODO: is it actually needed to convert to mV?\n",
    "\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data preprocessing\n",
    "## Extract ECG signals and class labels"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_labels = pd.read_csv('data/Physionet2017TrainingLabels.csv', header=None, names=['label'])\n",
    "df_labels['classification'] = df_labels['label'].replace({\"N\": 0, \"A\": 1})\n",
    "df_labels['label'] = df_labels['label'].replace({\"N\": 'Normal Sinus Rhythm', \"A\": 'Atrial Fibrillation'})\n",
    "# 0: Normal Sinus Rhythm\n",
    "# 1: Atrial Fibrillation"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_labels",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset splitting"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_labeled = pd.merge(df_labels.drop(columns='label'), df, left_on='classification', right_index=True)\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    df.index,\n",
    "    test_size=0.2,\n",
    "    stratify=df_labels[\"label\"],\n",
    "    random_state=3003\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(train_idx))\n",
    "print(\"Test size:\", len(test_idx))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Functions Definitions"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Correlation plot"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Correlation plot\n",
    "def corr_plot_hrv(df, cols=None):\n",
    "    \"\"\"\n",
    "    Correlation heatmap for HRV features.\n",
    "    \"\"\"\n",
    "    data = df[cols] if cols else df.select_dtypes(\"number\")\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(data.corr(), cmap=\"coolwarm\", center=0)\n",
    "    plt.title(\"Correlation Map (HRV Features)\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Distribution plots"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Distribution plots\n",
    "def distplots_hrv(df, cols=None):\n",
    "    \"\"\"\n",
    "    Distribution plots (hist + KDE) for HRV features.\n",
    "    \"\"\"\n",
    "    data = df[cols] if cols else df.select_dtypes(\"number\")\n",
    "    for col in data.columns:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.histplot(data[col], kde=True)\n",
    "        plt.title(f\"Distribution of {col}\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def distplots(df):\n",
    "    numeric_df = df.select_dtypes(include=['number'])\n",
    "    num_features = len(numeric_df.columns)\n",
    "    cols = int(np.ceil(np.sqrt(num_features)))\n",
    "    rows = int(np.ceil(num_features / cols))\n",
    "\n",
    "    # A figure with subplots looks much nicer\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 4))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, column in enumerate(numeric_df.columns):\n",
    "        # Replace inf with NaN and then drop NaNs\n",
    "        numeric_df_nona = numeric_df[column].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "        axes[i].hist(numeric_df_nona, bins=30, alpha=0.7, edgecolor='black')\n",
    "\n",
    "        if len(numeric_df_nona) > 1:\n",
    "            density = stats.gaussian_kde(numeric_df_nona)\n",
    "            xs = np.linspace(numeric_df_nona.min(), numeric_df_nona.max(), 200)\n",
    "            axes[i].plot(xs, density(xs) * len(numeric_df_nona) * (numeric_df_nona.max() - numeric_df_nona.min()) / 30,\n",
    "                         'r-', linewidth=2)\n",
    "\n",
    "        axes[i].set_xlabel(column)\n",
    "        axes[i].set_ylabel('Number of Patients')\n",
    "        axes[i].set_title(f'Distribution of {column}')\n",
    "        axes[i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "    # Remove any empty subplots if they exist\n",
    "    for j in range(num_features, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Boxplots"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Boxplots\n",
    "def boxplots_hrv(df, cols):\n",
    "    \"\"\"\n",
    "    Boxplots for detecting unusual HRV values.\n",
    "    \"\"\"\n",
    "    for col in cols:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.boxplot(y=df[col])\n",
    "        plt.title(f\"Boxplot of {col}\")\n",
    "        plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Missingness overview"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Missingness\n",
    "def check_missing_hrv(df):\n",
    "    \"\"\"\n",
    "    Summarize missingness across HRV features.\n",
    "    \"\"\"\n",
    "    missing = df.isna().sum()\n",
    "    out = pd.DataFrame({\n",
    "        \"feature\": df.columns,\n",
    "        \"missing_n\": missing,\n",
    "        \"missing_%\": (missing / len(df)) * 100\n",
    "    })\n",
    "    display(out.sort_values(\"missing_%\", ascending=False))\n",
    "    return out"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Exploratory Data Analysis\n",
    "## Dataset characteristics"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_ecgs = len(df)  # Number of ECGs\n",
    "\n",
    "num_samples = df.shape[1]  # Number of samples per ECG\n",
    "\n",
    "sampling_frequency = 300  #Hz\n",
    "duration = num_samples / sampling_frequency  # Duration of each ECG\n",
    "\n",
    "class_distribution = df_labels['label'].value_counts()  # Distribution over classes #TODO: quick pie chart?\n",
    "\n",
    "print(f\"Number of ECGs: {num_ecgs}\")\n",
    "print(f\"Number of samples per ECG: {num_samples}\")\n",
    "print(f\"Duration of each ECG: {duration} seconds\")\n",
    "print(f\"\\nClass Distribution:\\n{class_distribution}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Indices per class (based on df_labels)\n",
    "sinus_indices = df_labels[df_labels[\"label\"] == \"Normal Sinus Rhythm\"].index.tolist()\n",
    "af_indices = df_labels[df_labels[\"label\"] == \"Atrial Fibrillation\"].index.tolist()\n",
    "\n",
    "example_sinus_idx = random.choice(sinus_indices)\n",
    "example_af_idx = random.choice(af_indices)\n",
    "\n",
    "ecg_sinus_raw = df.iloc[example_sinus_idx].astype(float).values\n",
    "ecg_af_raw = df.iloc[example_af_idx].astype(float).values\n",
    "\n",
    "time = np.arange(0, len(ecg_sinus_raw)) / sampling_frequency\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.plot(time, ecg_sinus_raw, label=f\"NSR (index {example_sinus_idx})\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Voltage (mV)\")\n",
    "plt.title(\"Example raw ECG – Normal Sinus Rhythm\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.plot(time, ecg_af_raw, label=f\"AF (index {example_af_idx})\", color=\"orange\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Voltage (mV)\")\n",
    "plt.title(\"Example raw ECG – Atrial Fibrillation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Summary statistics for each ECG\n",
    "summary_stats = df.describe().T\n",
    "summary_stats = pd.concat([summary_stats, df_labels], axis=1)\n",
    "\n",
    "# Plotting the distributions of summary statistics\n",
    "stats_to_plot = ['mean', 'std', 'min', 'max', '25%', '75%']\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, stat in enumerate(stats_to_plot):\n",
    "    sns.kdeplot(ax=axes[i], data=summary_stats, x=stat, hue='label', fill=True, common_norm=False)\n",
    "    axes[i].set_title(f'Distribution of voltage {stat} by rhythm category')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "counts = df_labels.label.value_counts().tolist()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(counts, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Rhythm Distribution')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ECG exploration\n",
    "Let's have a look at the ECG signals. The AliveCor ECGs are single lead ECGs, similar to **Lead I** in a standard 12-lead ECG. First, we determine which ECGs are in Normal Sinus Rhythm, and which ECGs are in Atrial Fibrillation"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Randomly select ECGs from each class\n",
    "number_of_selectedECGs = 1  # change to plot more ECGs for each rhythm category\n",
    "selected_sinus_indices = random.sample(sinus_indices, number_of_selectedECGs)\n",
    "selected_af_indices = random.sample(af_indices, number_of_selectedECGs)\n",
    "\n",
    "# Create subplots\n",
    "fig = make_subplots(rows=number_of_selectedECGs, cols=2, subplot_titles=(\"Normal Sinus Rhythm\", \"Atrial Fibrillation\"))\n",
    "\n",
    "# Plot NSR ECGs on the left subplot\n",
    "for i, index in enumerate(selected_sinus_indices):\n",
    "    time = np.arange(0, len(df.iloc[index])) / sampling_frequency  # Assuming sampling_frequency is defined\n",
    "    fig.add_trace(go.Scatter(x=time, y=df.iloc[index], mode='lines', name=f'ECG {index + 1}'), row=i + 1, col=1)\n",
    "\n",
    "# Plot AF ECGs on the right subplot\n",
    "for i, index in enumerate(selected_af_indices):\n",
    "    time = np.arange(0, len(df.iloc[index])) / sampling_frequency  # Assuming sampling_frequency is defined\n",
    "    fig.add_trace(go.Scatter(x=time, y=df.iloc[index], mode='lines', name=f'ECG {index + 1}'), row=i + 1, col=2)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title_text=\"Selected ECGs: NSR vs. AF\",\n",
    "                  xaxis_title='Time (s)',\n",
    "                  yaxis_title='Voltage (mV)',\n",
    "                  showlegend=False, )\n",
    "\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ECG frequency analysis\n",
    "An important feature of any signal is the frequency content: it tells us which frequency a predominantly present in the signal. In this case, differences in cardiac rhythm may be associated with differences in frequency content. The following code computes the frequency content of an ECG signal using the *Fourier transform* (`fft` in Python).\n",
    "\n",
    "**Question:** how could we differentiate between NSR and AF based on the frequency content?"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Show the frequency content of each of the selected ECGs\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "# Create subplots\n",
    "num_ecgs = len(selected_sinus_indices) + len(selected_af_indices)\n",
    "\n",
    "subplot_titles = []\n",
    "for index in selected_sinus_indices + selected_af_indices:\n",
    "    subplot_titles.extend([f\"ECG {index + 1}\", f\"FFT {index + 1}\"])\n",
    "\n",
    "fig = make_subplots(rows=num_ecgs, cols=2, subplot_titles=subplot_titles)\n",
    "\n",
    "# Plot selected ECGs and their FFTs\n",
    "row_num = 1\n",
    "for index in selected_sinus_indices + selected_af_indices:\n",
    "    ecg_signal = df.iloc[index].astype(float)\n",
    "    time = np.arange(0, len(ecg_signal)) / sampling_frequency\n",
    "\n",
    "    # Calculate FFT\n",
    "    ecg_data = np.asarray(ecg_signal)\n",
    "    N = len(ecg_data)\n",
    "    yf = fft(ecg_data)\n",
    "    xf = fftfreq(N, 1 / sampling_frequency)\n",
    "    xf = xf[:N // 2]  # Only consider positive frequencies\n",
    "    yf = 2.0 / N * np.abs(yf[:N // 2])\n",
    "\n",
    "    # Plot ECG on the left subplot\n",
    "    fig.add_trace(go.Scatter(x=time, y=ecg_signal, mode='lines', name=f'ECG {index + 1}'), row=row_num, col=1)\n",
    "\n",
    "    # Plot FFT on the right subplot\n",
    "    fig.add_trace(go.Scatter(x=xf, y=yf, mode='lines', name=f'FFT {index + 1}'), row=row_num, col=2)\n",
    "\n",
    "    row_num += 1\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title_text=\"Selected ECGs and FFTs\",\n",
    "                  xaxis_title='Time (s)',\n",
    "                  xaxis2_title='Frequency (Hz)',\n",
    "                  yaxis_title='Amplitude',\n",
    "                  yaxis2_title='Magnitude',\n",
    "                  showlegend=False,\n",
    "                  height=num_ecgs * 300)  # Adjust height based on the number of ECGs\n",
    "\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The *Welch periodogram* is an approach to estimate the frequency content of a signal that computes the *average* spectrogram of overlapping signal segments."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compute the Welch periodogram instead of the fft\n",
    "# Show the frequency content of each of the selected ECGs using Welch's method\n",
    "\n",
    "# Create subplots\n",
    "num_ecgs = len(selected_sinus_indices) + len(selected_af_indices)\n",
    "\n",
    "subplot_titles = []\n",
    "for index in selected_sinus_indices + selected_af_indices:\n",
    "    subplot_titles.extend([f\"ECG {index + 1}\", f\"Welch Periodogram {index + 1}\"])\n",
    "\n",
    "fig = make_subplots(rows=num_ecgs, cols=2, subplot_titles=subplot_titles)\n",
    "\n",
    "# Plot selected ECGs and their Welch periodograms\n",
    "numberOfSamplesPerFFT = 1024\n",
    "row_num = 1\n",
    "for index in selected_sinus_indices + selected_af_indices:\n",
    "    ecg_signal = df.iloc[index].astype(float)\n",
    "    time = np.arange(0, len(ecg_signal)) / sampling_frequency\n",
    "\n",
    "    # Calculate Welch periodogram\n",
    "    ecg_data = np.asarray(ecg_signal)  # Convert pandas Series to NumPy array\n",
    "    frequencies, power_spectrum = welch(ecg_data, fs=sampling_frequency, nperseg=numberOfSamplesPerFFT)\n",
    "\n",
    "    # Plot ECG on the left subplot\n",
    "    fig.add_trace(go.Scatter(x=time, y=ecg_signal, mode='lines', name=f'ECG {index + 1}'), row=row_num, col=1)\n",
    "\n",
    "    # Plot Welch periodogram on the right subplot\n",
    "    fig.add_trace(go.Scatter(x=frequencies, y=power_spectrum, mode='lines', name=f'Welch {index + 1}'), row=row_num,\n",
    "                  col=2)\n",
    "\n",
    "    row_num += 1\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title_text=\"Selected ECGs and Welch Periodograms\",\n",
    "                  xaxis_title='Time (s)',\n",
    "                  xaxis2_title='Frequency (Hz)',\n",
    "                  yaxis_title='Amplitude',\n",
    "                  yaxis2_title='Power Spectral Density',\n",
    "                  showlegend=False,\n",
    "                  height=num_ecgs * 300)  # Adjust height based on the number of ECGs\n",
    "\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Feature extraction"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Powerline interference"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#TODO: Remove this, it's unnecessary overhead from the parctical\n",
    "ecg_sim = nk.ecg_simulate(duration=5, sampling_rate=sampling_frequency, method=\"ecgsyn\")\n",
    "time = np.arange(0, len(ecg_sim)) / sampling_frequency\n",
    "\n",
    "# Add a 50Hz signal\n",
    "frequency = 50  # Hz\n",
    "amplitude = 0.1  # Adjust the amplitude as needed\n",
    "signal_50hz = amplitude * np.sin(2 * np.pi * frequency * time)\n",
    "\n",
    "# Add the 50Hz signal to ecg_sim\n",
    "ecg_sim_with_50hz = ecg_sim + signal_50hz\n",
    "\n",
    "# Plot both signals\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=time, y=ecg_sim_with_50hz, mode='lines', name='ECG with 50Hz Noise'))\n",
    "fig.add_trace(go.Scatter(x=time, y=ecg_sim, mode='lines', name='Original ECG'))\n",
    "fig.update_layout(title_text=\"ECG Signals: Original vs. with 50Hz Noise\",\n",
    "                  xaxis_title=\"Time (s)\",\n",
    "                  yaxis_title=\"Amplitude\")\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compute and show the Welch periodogram of the 50Hz ecg signal\n",
    "frequencies, power_spectrum = welch(ecg_sim_with_50hz, fs=sampling_frequency, nperseg=1024)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=frequencies, y=power_spectrum, mode='lines', name='Welch Periodogram'))\n",
    "fig.update_layout(title_text=\"Welch Periodogram of 50Hz ECG Signal\",\n",
    "                  xaxis_title=\"Frequency (Hz)\",\n",
    "                  yaxis_title=\"Power Spectral Density\")\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we create a so-called *notch filter*: this is a filter that supresses a certain frequency in a signal, in this case 50Hz"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Standard signal processing algorithm can be found in the package scipy.signal\n",
    "import scipy.signal as signal\n",
    "\n",
    "# filter design\n",
    "notch_freq = 50  # frequency that we want to filter out\n",
    "quality_factor = 30\n",
    "nyquist_freq = 0.5 * sampling_frequency\n",
    "normalized_notch_freq = notch_freq / nyquist_freq\n",
    "b, a = signal.iirnotch(normalized_notch_freq, quality_factor)\n",
    "\n",
    "# apply the filter to the signal with noise\n",
    "filtered_ecg = signal.filtfilt(b, a, ecg_sim_with_50hz)\n",
    "\n",
    "# Plot the original signal with noise and filtered signal\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=time, y=ecg_sim_with_50hz, mode='lines', name='ECG with 50Hz Noise'))\n",
    "fig.add_trace(go.Scatter(x=time, y=ecg_sim, mode='lines', name='Original ECG'))\n",
    "fig.add_trace(go.Scatter(x=time, y=filtered_ecg, mode='lines', name='Filtered ECG'))\n",
    "\n",
    "fig.update_layout(title_text=\"ECG Signals: with 50Hz Noise vs. Filtered\",\n",
    "                  xaxis_title=\"Time (s)\",\n",
    "                  yaxis_title=\"Amplitude\")\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###Baseline wander"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Simulate an ECG\n",
    "sampling_frequency = 300  # Hz\n",
    "ecg_sim = nk.ecg_simulate(duration=10, sampling_rate=sampling_frequency, method=\"ecgsyn\")\n",
    "time = np.arange(0, len(ecg_sim)) / sampling_frequency\n",
    "\n",
    "# Add baseline wander\n",
    "wander = 0.5 * np.sin(2 * np.pi * 0.3 * time)  # 0.3 Hz baseline wander\n",
    "ecg_wander = ecg_sim + wander\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=time, y=ecg_wander, mode='lines', name='ECG with Wander'))\n",
    "fig.add_trace(go.Scatter(x=time, y=ecg_sim, mode='lines', name='Original ECG'))\n",
    "fig.update_layout(title_text=\"ECG Signals: Baseline Wandering\",\n",
    "                  xaxis_title=\"Time (s)\",\n",
    "                  yaxis_title=\"Amplitude\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compute and show the Welch periodogram of the baseline wander ecg signal\n",
    "frequencies, power_spectrum = welch(ecg_wander, fs=sampling_frequency, nperseg=1024)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=frequencies, y=power_spectrum, mode='lines', name='Welch Periodogram'))\n",
    "fig.update_layout(title_text=\"Welch Periodogram of baseline wander ECG Signal\",\n",
    "                  xaxis_title=\"Frequency (Hz)\",\n",
    "                  yaxis_title=\"Power Spectral Density\")\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Apply a median filter\n",
    "window_size = 101  # Adjust window size as needed\n",
    "ecg_median_filtered = ecg_wander - signal.medfilt(ecg_wander, kernel_size=window_size)\n",
    "\n",
    "# Apply a 0.5Hz high-pass filter\n",
    "cutoff_freq = 0.5  # Hz\n",
    "nyquist_freq = 0.5 * sampling_frequency\n",
    "normalized_cutoff = cutoff_freq / nyquist_freq\n",
    "b, a = signal.butter(4, normalized_cutoff, btype='high', analog=False)\n",
    "ecg_highpass_filtered = signal.filtfilt(b, a, ecg_wander)\n",
    "\n",
    "# Plot the results\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=time, y=ecg_wander, mode='lines', name='ECG with Wander'))\n",
    "fig.add_trace(go.Scatter(x=time, y=ecg_sim, mode='lines', name='Original ECG'))\n",
    "fig.add_trace(go.Scatter(x=time, y=ecg_median_filtered, mode='lines', name='ECG Median Filtered'))\n",
    "fig.add_trace(go.Scatter(x=time, y=ecg_highpass_filtered, mode='lines', name='ECG High-pass Filtered'))\n",
    "\n",
    "fig.update_layout(title_text=\"ECG Signals: Baseline Wander Removal Comparison\",\n",
    "                  xaxis_title=\"Time (s)\",\n",
    "                  yaxis_title=\"Amplitude\")\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###Muscle noise"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Generate EMG noise at random intervals\n",
    "emg_noise = np.zeros_like(ecg_sim)\n",
    "\n",
    "std_dev_emg_noise = 0.05\n",
    "duration_emg_noise = int(0.05 * sampling_frequency)\n",
    "\n",
    "for _ in range(10 * 20):  # Assuming an average of 20 contractions per second\n",
    "    start = np.random.randint(0, len(ecg_sim) - duration_emg_noise)\n",
    "    emg_noise[start:start + duration_emg_noise] += np.random.normal(0, std_dev_emg_noise, duration_emg_noise)\n",
    "\n",
    "# Combine ECG signal with EMG noise\n",
    "ecg_muscle = ecg_sim + emg_noise\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=time, y=ecg_sim, mode='lines', name='Original ECG'))\n",
    "fig.add_trace(go.Scatter(x=time, y=ecg_muscle, mode='lines', name='ECG with Muscle Noise'))\n",
    "fig.update_layout(title_text=\"ECG Signals: Muscle Noise\",\n",
    "                  xaxis_title=\"Time (s)\",\n",
    "                  yaxis_title=\"Amplitude\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Apply a 100Hz low-pass filter\n",
    "cutoff_freq = 100  # Hz\n",
    "nyquist_freq = 0.5 * sampling_frequency\n",
    "normalized_cutoff = cutoff_freq / nyquist_freq\n",
    "b, a = signal.butter(4, normalized_cutoff, btype='low', analog=False)\n",
    "ecg_lowpass_filtered = signal.filtfilt(b, a, ecg_sim)\n",
    "\n",
    "# Plot the original signal with noise and filtered signal\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=time, y=ecg_muscle, mode='lines', name='ECG with Muscle Noise'))\n",
    "fig.add_trace(go.Scatter(x=time, y=ecg_lowpass_filtered, mode='lines', name='ECG Low-pass Filtered'))\n",
    "fig.add_trace(go.Scatter(x=time, y=ecg_sim, mode='lines', name='Original ECG',\n",
    "                         line=dict(color='gray', width=1.5)))\n",
    "fig.update_layout(title_text=\"ECG Signals: with Muscle Noise vs. Filtered\",\n",
    "                  xaxis_title=\"Time (s)\",\n",
    "                  yaxis_title=\"Amplitude\")\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##ECG feature engineering"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Tradionally, ECG analysis is done visually, with a cardiologist/electrophysiologist that assesses the ECG signal(s) and makes a diagnosis based on standardized criteria (for instance the [Minnesota Code](https://link.springer.com/book/10.1007/978-1-84882-778-3)). Conventional ECG analysis tool translate these criteria into a set of automated algorithms that extract features that can then be used to classify the rhythm on an ECG. Standard criteria to diagnose AF from an ECG are:\n",
    "- Required\n",
    "  - Absence of a visible P-wave\n",
    "  - Irregularly irregular heart rhythm\n",
    "- Optional\n",
    "  - Presence of f-waves / absence of isoelectric baseline\n",
    "  - Fast ventricular rate\n",
    "\n",
    "In this workshop we will focuse on crafting features related to heart rate variability, as the visibility of the P-wave is often limited in lead I, due to its low amplitude."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###Feature extraction using NeuroKit\n",
    "\n",
    "NeuroKit can be used to process ECG and compute features related to *heart rate variability* (HRV). See https://doi.org/10.3390/s21123998 for an overview of HRV features.\n",
    "\n",
    "The package computes features in 3 domains:\n",
    "- *time domain*: features based on variability in the heart rate intervals (R-R intervals)\n",
    "- *frequency domain*: frequency content of the R-R interval series, reflecting parasympathetic and sympathetic activity\n",
    "- *nonlinear dynamics*: features that try to capture the underlying dynamics of the R-R series. The Poincare plot is a well-known example of a nonlinear analysis."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Select an ECG in Normal Sinus Rhythm and one in AF and process them\n",
    "selected_sinus_indices = random.sample(sinus_indices, 1)\n",
    "selected_af_indices = random.sample(af_indices, 1)\n",
    "\n",
    "ecg_NSR = df.iloc[selected_sinus_indices[0]].astype(float)\n",
    "signals_NSR, info_NSR = nk.ecg_process(ecg_NSR, sampling_rate=sampling_frequency)\n",
    "\n",
    "# Visualise the processing\n",
    "plt.rcParams['figure.figsize'] = [12, 4]\n",
    "nk.ecg_plot(signals_NSR, info_NSR)\n",
    "\n",
    "ecg_AF = df.iloc[selected_af_indices[0]].astype(float)\n",
    "signals_AF, info_AF = nk.ecg_process(ecg_AF, sampling_rate=sampling_frequency)\n",
    "\n",
    "# Visualise the processing\n",
    "nk.ecg_plot(signals_AF, info_AF)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "####**R-peaks**"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Find R-peaks\n",
    "peaks_NSR, info_NSR = nk.ecg_peaks(ecg_NSR, sampling_rate=sampling_frequency, correct_artifacts=True, show=True)\n",
    "peaks_AF, info_AF = nk.ecg_peaks(ecg_AF, sampling_rate=sampling_frequency, correct_artifacts=True, show=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Time-domain features"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Time domain features NSR\n",
    "hrv_time_NSR = nk.hrv_time(peaks_NSR, sampling_rate=sampling_frequency, show=True)\n",
    "hrv_time_NSR"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Time domain features AF\n",
    "hrv_time_AF = nk.hrv_time(peaks_AF, sampling_rate=sampling_frequency, show=True)\n",
    "hrv_time_AF"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### FULL HRV feature extraction for all ECGs (TRAIN)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Getting all the ECG readouts so we can extract P-wave information\n",
    "\n",
    "def get_ECG_readout():\n",
    "    test_run = 0\n",
    "    ecg_full = pd.DataFrame()  # Initialize an empty DataFrame\n",
    "\n",
    "    for i in tqdm(train_idx):\n",
    "\n",
    "        ecg = df.iloc[i].astype(float)\n",
    "        signals, info = nk.ecg_process(ecg, sampling_rate=sampling_frequency)\n",
    "\n",
    "        # Assign the current ecg_index to the signals DataFrame before concatenation\n",
    "        signals[\"ecg_index\"] = i\n",
    "\n",
    "        ecg_full = pd.concat([ecg_full, signals], ignore_index=True)\n",
    "\n",
    "        test_run += 1\n",
    "\n",
    "        if test_run == 10:\n",
    "            break  # Stop after 10 iterations for the example\n",
    "\n",
    "    return ecg_full"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ecg_full = get_ECG_readout()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_ECG_metrics(ecg_full):\n",
    "    ecg_metrics_list = []\n",
    "\n",
    "    for i in tqdm(train_idx[:10]):\n",
    "        mean_quality = ecg_full.loc[ecg_full.ecg_index == i]['ECG_Quality'].mean()\n",
    "        mean_pwave_amplitude = ecg_full.loc[(ecg_full.ecg_index == i) & (ecg_full['ECG_P_Peaks'] == 1)][\n",
    "            'ECG_Clean'].mean()  #You could consider taking sqrt, mean and then **2\n",
    "        #(more robust) to outliers\n",
    "        stdev_pwave = ecg_full.loc[(ecg_full.ecg_index == i) & (ecg_full['ECG_P_Peaks'] == 1)]['ECG_Quality'].std()\n",
    "        #Perhaps I could add something about irregularly irregular rhythm, but it's (really) difficult mathematically\n",
    "        ecg_metrics_list.append({\n",
    "            'Mean_Quality': mean_quality,\n",
    "            'Mean_PWave_Amplitude': mean_pwave_amplitude,\n",
    "            'STDEV_Pwave': stdev_pwave,\n",
    "            'ecg_index': i\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(ecg_metrics_list)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ecg_metrics = get_ECG_metrics(ecg_full)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#FULL HRV feature extraction for all ECGs (TRAIN)\n",
    "\n",
    "hrv_features_train = []\n",
    "\n",
    "for i in tqdm(train_idx, desc=\"HRV (ALL FEATURES): TRAIN SET\"):\n",
    "    # Grab raw ECG\n",
    "    ecg = df.iloc[i].astype(float).values\n",
    "\n",
    "    try:\n",
    "        # 1. Clean ECG\n",
    "        ecg_clean = nk.ecg_clean(ecg, sampling_rate=sampling_frequency)\n",
    "\n",
    "        # 2. Detect R-peaks\n",
    "        peaks, _ = nk.ecg_peaks(\n",
    "            ecg_clean,\n",
    "            sampling_rate=sampling_frequency,\n",
    "            correct_artifacts=True\n",
    "        )\n",
    "\n",
    "        # 3. Compute FULL HRV feature set\n",
    "        hrv_full = nk.hrv(\n",
    "            peaks,\n",
    "            sampling_rate=sampling_frequency,\n",
    "            show=False\n",
    "        )\n",
    "\n",
    "        # Ensure row is a proper 1-row DataFrame and add ecg_index\n",
    "        hrv_full = hrv_full.copy()\n",
    "        hrv_full[\"ecg_index\"] = i\n",
    "\n",
    "        hrv_features_train.append(hrv_full)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing TRAIN ECG {i}: {e}\")\n",
    "\n",
    "        if hrv_features_train:\n",
    "            empty = pd.DataFrame(\n",
    "                [np.nan] * hrv_features_train[0].shape[1],\n",
    "                index=hrv_features_train[0].columns\n",
    "            ).T\n",
    "            empty[\"ecg_index\"] = i\n",
    "            hrv_features_train.append(empty)\n",
    "\n",
    "# Combine to single DataFrame\n",
    "hrv_train = pd.concat(hrv_features_train, ignore_index=True)\n",
    "\n",
    "print(\"hrv_train shape:\", hrv_train.shape)\n",
    "hrv_train.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Merge our new dataframe with our extra variables\n",
    "hrv_train = pd.merge(hrv_train, ecg_metrics, on='ecg_index', how='left')\n",
    "hrv_train.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Remove all columns from the dataframe that contain more than 50% NaN\n",
    "threshold = 0.5\n",
    "hrv_train_clean = hrv_train.dropna(thresh=len(hrv_train) * threshold, axis=1)\n",
    "\n",
    "# Remove all rows that are all NaN\n",
    "hrv_train_clean = hrv_train_clean.dropna(how='all')\n",
    "\n",
    "hrv_train_clean.to_csv(\"hrv_train.csv\", index=False)\n",
    "hrv_train_clean.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### FULL HRV feature extraction for all ECGs (TEST)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hrv_features_test = []\n",
    "\n",
    "for i in tqdm(test_idx, desc=\"HRV (ALL FEATURES): TEST SET\"):\n",
    "    ecg = df.iloc[i].astype(float).values\n",
    "\n",
    "    try:\n",
    "        # 1. Clean ECG\n",
    "        ecg_clean = nk.ecg_clean(ecg, sampling_rate=sampling_frequency)\n",
    "\n",
    "        # 2. Detect R-peaks\n",
    "        peaks, _ = nk.ecg_peaks(\n",
    "            ecg_clean,\n",
    "            sampling_rate=sampling_frequency,\n",
    "            correct_artifacts=True\n",
    "        )\n",
    "\n",
    "        # 3. Compute FULL HRV feature set\n",
    "        hrv_full = nk.hrv(\n",
    "            peaks,\n",
    "            sampling_rate=sampling_frequency,\n",
    "            show=False\n",
    "        )\n",
    "\n",
    "        # Same as TRAIN: keep as 1-row DataFrame, add index\n",
    "        hrv_full = hrv_full.copy()\n",
    "        hrv_full[\"ecg_index\"] = i\n",
    "\n",
    "        hrv_features_test.append(hrv_full)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing TEST ECG {i}: {e}\")\n",
    "\n",
    "        if hrv_features_test:\n",
    "            empty = pd.DataFrame(\n",
    "                [np.nan] * hrv_features_test[0].shape[1],\n",
    "                index=hrv_features_test[0].columns\n",
    "            ).T\n",
    "            empty[\"ecg_index\"] = i\n",
    "            hrv_features_test.append(empty)\n",
    "\n",
    "hrv_test = pd.concat(hrv_features_test, ignore_index=True)\n",
    "\n",
    "print(\"hrv_test shape:\", hrv_test.shape)\n",
    "hrv_test.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Merge our new dataframe with our extra variables\n",
    "hrv_test = pd.merge(hrv_test, ecg_metrics, on='ecg_index', how='left')\n",
    "hrv_test.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Remove all columns from the dataframe that contain more than 50% NaN\n",
    "threshold = 0.5\n",
    "hrv_test_clean = hrv_test.dropna(thresh=len(hrv_test) * threshold, axis=1)\n",
    "\n",
    "# Remove all rows that are all NaN\n",
    "hrv_test_clean = hrv_test_clean.dropna(how='all')\n",
    "\n",
    "hrv_test_clean.head()\n",
    "\n",
    "hrv_test.to_csv(\"hrv_test.csv\", index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Feature exploration"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Merge the HRV data with the rhythm labels\n",
    "hrv_train_with_labels = pd.merge(\n",
    "    hrv_train_clean, df_labels, left_on='ecg_index', right_index=True\n",
    ").reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "selectedMetric = 'HRV_MedianNN'\n",
    "rhythms = hrv_train_with_labels['label'].unique()\n",
    "for rhythm in rhythms:\n",
    "    subset = hrv_train_with_labels[hrv_train_with_labels['label'] == rhythm]\n",
    "    plt.hist(subset[selectedMetric], alpha=0.7, label=rhythm, bins='auto')\n",
    "\n",
    "plt.xlabel(selectedMetric)\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution by Rhythm')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualisations"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Correlation plot"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Adding the feature cols\n",
    "feature_cols = [col for col in hrv_train_with_labels.columns if col.startswith(\"HRV_\")]\n",
    "\n",
    "# Correlation heatmap\n",
    "corr_plot_hrv(hrv_train_clean)\n",
    "\n",
    "# Quick ranking: strongest HRV–AF correlations (top 10)\n",
    "hrv_only = hrv_train_with_labels[feature_cols + [\"classification\"]]\n",
    "corr_with_af = hrv_only.corr()[\"classification\"].sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 10 HRV features correlated with AF:\")\n",
    "print(corr_with_af.head(10))\n",
    "\n",
    "print(\"\\nBottom 10 (most negative):\")\n",
    "print(corr_with_af.tail(10))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Distribution plots"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "distplots(hrv_train_clean)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "distplots_hrv(hrv_train_clean)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Boxplots"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Boxplots\n",
    "boxplots_hrv(hrv_train_clean, [\"HRV_MedianNN\", \"HRV_SDNN\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Missingness"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Missingness\n",
    "check_missing_hrv(hrv_train_clean)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Outlier Detection"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Function to identify outliers in the data\n",
    "def identify_outliers(df, column_name, threshold=1.5):\n",
    "    # Calculate Q1, Q3, and IQR\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define outlier bounds\n",
    "    lower_bound = Q1 - threshold * IQR\n",
    "    upper_bound = Q3 + threshold * IQR\n",
    "\n",
    "    # Identify outliers\n",
    "    row_indices = df[(df[column_name] < lower_bound) | (df[column_name] > upper_bound)].index.tolist()\n",
    "    outlier_values = df.loc[row_indices, column_name].tolist()\n",
    "\n",
    "    return row_indices, outlier_values, lower_bound, upper_bound"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Outlier detection ONLY ON TRAIN\n",
    "\n",
    "# Merge labels with TRAIN features (cleaned hrv_train)\n",
    "hrv_train_with_labels = pd.merge(\n",
    "    hrv_train_clean, df_labels, left_on=\"ecg_index\", right_index=True\n",
    ")\n",
    "\n",
    "# Outlier detection ONLY on TRAIN\n",
    "train_outlier_idx, outlier_values, iqr_lower, iqr_upper = identify_outliers(\n",
    "    hrv_train_with_labels,\n",
    "    \"HRV_MedianNN\",\n",
    "    threshold=1.5\n",
    ")\n",
    "\n",
    "# ecg_index as (int)\n",
    "hrv_train_with_labels[\"ecg_index\"] = hrv_train_with_labels[\"ecg_index\"].astype(int)\n",
    "\n",
    "print(\"Train outliers detected:\", len(train_outlier_idx))\n",
    "print(\"Row indices (in hrv_train_with_labels) with outliers:\", train_outlier_idx)\n",
    "print(\"Outlier HRV_MedianNN values:\", outlier_values)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualise one outlier ECG\n",
    "\n",
    "example_outlier_row = train_outlier_idx[0]\n",
    "\n",
    "# Single row\n",
    "row = hrv_train_with_labels.loc[example_outlier_row]\n",
    "\n",
    "# Extract ECG index value\n",
    "ecg_index_values = row.filter(like=\"ecg_index\").values\n",
    "\n",
    "# Use first value\n",
    "ecg_idx = int(ecg_index_values[0])\n",
    "\n",
    "# Extract raw ECG from df\n",
    "ecg_raw = df.iloc[ecg_idx].astype(float).values\n",
    "\n",
    "# Visualise R-Peaks\n",
    "peaks_outlier, info_outlier = nk.ecg_peaks(\n",
    "    ecg_raw,\n",
    "    sampling_rate=sampling_frequency,\n",
    "    correct_artifacts=True,\n",
    "    show=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "hrv_train_with_labels.loc[example_outlier_row]",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### **Outliers TEST set** done the same way as for TRAINING"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Align TEST columns to TRAIN columns\n",
    "\n",
    "# Align TEST columns to TRAIN columns (no leakage, same feature space)\n",
    "train_cols = hrv_train_clean.columns  # already cleaned on TRAIN\n",
    "shared_cols = [c for c in train_cols if c in hrv_test.columns]\n",
    "\n",
    "hrv_test_aligned = hrv_test[shared_cols].copy()\n",
    "\n",
    "# Merge TEST HRV with labels\n",
    "hrv_test_with_labels = pd.merge(\n",
    "    hrv_test_aligned,\n",
    "    df_labels[[\"label\", \"classification\"]],\n",
    "    left_on=\"ecg_index\",\n",
    "    right_index=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Same IQR bounds as on hrv_train\n",
    "\n",
    "Q1 = hrv_train_clean[\"HRV_MedianNN\"].quantile(0.25)\n",
    "Q3 = hrv_train_clean[\"HRV_MedianNN\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "hrv_test_clean = hrv_test_with_labels[\n",
    "    (hrv_test_with_labels[\"HRV_MedianNN\"] >= lower_bound) &\n",
    "    (hrv_test_with_labels[\"HRV_MedianNN\"] <= upper_bound)\n",
    "    ].copy()\n",
    "\n",
    "print(\"hrv_test shape:\", hrv_test.shape)\n",
    "print(\"hrv_test_with_labels shape:\", hrv_test_with_labels.shape)\n",
    "print(\"hrv_test_clean shape:\", hrv_test_clean.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Distribution TRAIN + TEST | Sanity check"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(hrv_train_clean.columns[:5])\n",
    "print(hrv_test_clean.columns[:5])\n",
    "print(hrv_test_clean[[\"HRV_MedianNN\", \"classification\"]].head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for feat in [\"HRV_MedianNN\", \"HRV_SDNN\"]:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.kdeplot(\n",
    "        data=hrv_train_clean, x=feat, label=\"Train\", fill=True, common_norm=False\n",
    "    )\n",
    "    sns.kdeplot(\n",
    "        data=hrv_test_clean, x=feat, label=\"Test\", fill=True, common_norm=False, color=\"orange\"\n",
    "    )\n",
    "    plt.title(f\"{feat}: Train vs Test\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Outlier Handling TRAIN"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Winsorising outliers"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "Q1 = hrv_train_with_labels[\"HRV_MedianNN\"].quantile(0.25)\n",
    "Q3 = hrv_train_with_labels[\"HRV_MedianNN\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_clip = Q1 - 1.5 * IQR\n",
    "upper_clip = Q3 + 1.5 * IQR\n",
    "\n",
    "hrv_train_winsor = hrv_train_with_labels.copy()\n",
    "hrv_train_winsor[\"HRV_MedianNN_winsor\"] = hrv_train_with_labels[\"HRV_MedianNN\"].clip(\n",
    "    lower=lower_clip, upper=upper_clip\n",
    ")\n",
    "\n",
    "print(\"Shape after winsorizing (same as original):\", hrv_train_winsor.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Outlier Handling Comparison"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(hrv_train_with_labels[\"HRV_MedianNN\"], kde=True, color=\"red\", label=\"Original\")\n",
    "sns.histplot(hrv_train_winsor[\"HRV_MedianNN_winsor\"], kde=True, color=\"green\", label=\"Winsorized\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Outlier Handling Comparison\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Final Preprocessing: Building ML Matrices (X_train, X_test)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Select HRV feature columns only\n",
    "feature_cols = [col for col in hrv_train_with_labels.columns if col.startswith(\"HRV_\")]\n",
    "\n",
    "# TRAIN data\n",
    "x_train = hrv_train_with_labels[feature_cols].copy()\n",
    "y_train = hrv_train_with_labels[\"classification\"].copy()\n",
    "\n",
    "# TEST data\n",
    "x_test = hrv_test_clean[feature_cols].copy()\n",
    "y_test = hrv_test_clean[\"classification\"].copy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Replace +/- inf with NaN in both TRAIN and TEST\n",
    "for df_ in (x_train, x_test):\n",
    "    df_.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Drop columns that are all-NaN (if any)\n",
    "all_nan_cols = x_train.columns[x_train.isna().all()]\n",
    "if len(all_nan_cols) > 0:\n",
    "    print(\"Dropping all-NaN columns before imputation:\", list(all_nan_cols))\n",
    "    x_train.drop(columns=all_nan_cols, inplace=True)\n",
    "    x_test.drop(columns=all_nan_cols, inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imputation"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Median imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "# X_train: fit_transform\n",
    "X_train_imputed = imputer.fit_transform(x_train)\n",
    "\n",
    "# X_test: only transform (so test set remains untouched)\n",
    "X_test_imputed = imputer.transform(x_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Normalisation"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Temporarily convert to DataFrame to calculate Skewness easily\n",
    "temp_df = pd.DataFrame(X_train_imputed, columns=feature_cols)\n",
    "skewness = temp_df.skew().sort_values(ascending=False)\n",
    "\n",
    "#Identify skewed columns (Threshold > 1.0)\n",
    "skewed_cols = skewness[abs(skewness) > 1.0].index.tolist()\n",
    "\n",
    "#Apply Log Transform directly to the NumPy arrays\n",
    "for col_name in skewed_cols:\n",
    "    # Find the column index (integer position)\n",
    "    col_idx = feature_cols.index(col_name)\n",
    "\n",
    "    # Check for negative values (Log crashes on negatives)\n",
    "    # We find the global minimum for this column across Train and Test\n",
    "    min_val = min(X_train_imputed[:, col_idx].min(), X_test_imputed[:, col_idx].min())\n",
    "\n",
    "    shift = 0\n",
    "    if min_val < 0:\n",
    "        # If negatives exist, calculate a shift to make the minimum 0\n",
    "        shift = abs(min_val)\n",
    "\n",
    "    # Apply transformation in-place: Log(x + shift + 1)\n",
    "    X_train_imputed[:, col_idx] = np.log1p(X_train_imputed[:, col_idx] + shift)\n",
    "    X_test_imputed[:, col_idx] = np.log1p(X_test_imputed[:, col_idx] + shift)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Scaling"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# X_train: fit_transform\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "\n",
    "# X_test: only transform (so test set remains untouched)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Convert back to df with column names\n",
    "x_train = pd.DataFrame(X_train_scaled, columns=feature_cols)\n",
    "x_test = pd.DataFrame(X_test_scaled, columns=feature_cols)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **Sanity checks**"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Median X_train\n",
    "print(\"Median of scaled features (should be ~0):\")\n",
    "print(x_train.median().round(3))\n",
    "\n",
    "# IQR X_train\n",
    "print(\"\\nIQR of scaled features (should be ~1):\")\n",
    "print((x_train.quantile(0.75) - x_train.quantile(0.25)).round(3))\n",
    "\n",
    "#Checking skewness of the datasets\n",
    "skewness_train = x_train.skew().sort_values(ascending=False)\n",
    "skewness_test = x_train.skew().sort_values(ascending=False)\n",
    "# Filter for highly skewed columns (absolute skew > 1.0)\n",
    "high_skew_cols_train = skewness_train[abs(skewness_train) > 1.0]\n",
    "high_skew_cols_test = skewness_test[abs(skewness_test) > 1.0]\n",
    "\n",
    "print(len(high_skew_cols_train))\n",
    "print(len(high_skew_cols_test))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Boxplot scaled feature distributions\n",
    "\n",
    "X_train_imputed_df = pd.DataFrame(X_train_imputed, columns=feature_cols)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "sns.boxplot(data=X_train_imputed_df, ax=axes[0])\n",
    "axes[0].set_title(\"Before Scaling (Imputed HRV Features)\")\n",
    "axes[0].tick_params(axis='x', rotation=90)\n",
    "\n",
    "sns.boxplot(data=x_train, ax=axes[1])\n",
    "axes[1].set_title(\"After RobustScaler (X_train)\")\n",
    "axes[1].tick_params(axis='x', rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Final ML datasets (X_train, X_test, y_train, y_test"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Train size:\", len(train_idx))\n",
    "print(\"Test size:\", len(test_idx))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if True:\n",
    "    # Feature matrices (winsorised > imputation > scaling)\n",
    "    x_train = X_train_scaled\n",
    "    x_test = X_test_scaled\n",
    "\n",
    "    # Target vectors (created earlier from HRV + labels AF(0/1))\n",
    "    y_train = hrv_train_with_labels[\"classification\"].copy()\n",
    "    y_test = hrv_test_clean[\"classification\"].copy()\n",
    "\n",
    "    print(\"Final X_train shape:\", x_train.shape)\n",
    "    print(\"Final X_test shape:\", x_test.shape)\n",
    "    print(\"Final y_train shape:\", y_train.shape)\n",
    "    print(\"Final y_test shape:\", y_test.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Machine Learning Training Setup"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Safety check"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "assert len(x_train) == len(y_train), \"Misaligned TRAIN matrix and labels!\"\n",
    "assert len(x_test) == len(y_test), \"Misaligned TEST matrix and labels!\"\n",
    "\n",
    "assert not np.isnan(x_train).any(), \"NaNs detected in X_train!\"\n",
    "assert not np.isnan(x_test).any(), \"NaNs detected in X_test!\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Comparison framework"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "resultsTable = pd.DataFrame(columns=['Model', 'Accuracy', 'F1 Score', 'Precision', 'Recall', 'ROC', 'ROC_AUC', 'cm'])\n",
    "\n",
    "\n",
    "def modelResults(model, accuracy, f1, precision, recall, roc_auc, roc_cur, cm):\n",
    "    print(\n",
    "        f\"Model {model} evaluated. \\nAccuracy: {accuracy} \\nF1 Score: {f1} \\nPrecision: {precision} \\nRecall: {recall} \\nROC AUC: {roc_auc}\")\n",
    "    resultsTable.loc[len(resultsTable)] = [model, accuracy, f1, precision, recall, roc_cur, roc_auc, cm]\n",
    "    resultsTable.to_csv(\"trainingResults.csv\", index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\n",
    "    f\"X train length: {len(x_train)}\\n X test length: {len(x_test)} \\n Y train length: {len(y_train)}\\n Y test length: {len(y_test)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Machine Learning Training"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Logistic Regression"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### All features"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_LR = LogisticRegression(multi_class='auto', max_iter=1000, class_weight='balanced')\n",
    "model_LR.fit(x_train, y_train)\n",
    "\n",
    "y_pred_proba = model_LR.predict_proba(x_test)[:, 1]\n",
    "y_pred = model_LR.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "\n",
    "f1_score_baseline = f1_score(y_test, y_pred, average='binary')\n",
    "\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred, normalize='true')\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model_LR.classes_)\n",
    "disp.plot();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "modelResults(model_LR, accuracy, f1_score(y_test, y_pred), precision_score(y_test, y_pred),\n",
    "             recall_score(y_test, y_pred), roc_auc_score(y_test, y_pred_proba), roc_curve(y_test, y_pred_proba), cm)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Select features"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Check if training set is a numpy array\n",
    "if isinstance(x_train, np.ndarray):\n",
    "    x_train = pd.DataFrame(x_train, columns=feature_cols)\n",
    "    x_test = pd.DataFrame(x_test, columns=feature_cols)\n",
    "\n",
    "coeffs = np.abs(model_LR.coef_[0])\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': x_train.columns,\n",
    "    'Importance': coeffs\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "top_features = feature_importance_df['Feature'].head(10).tolist()\n",
    "print(top_features)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Baseline LR f1-score: {f1_score_baseline:.4f}\")\n",
    "#Kept for reproducibility purposes\n",
    "\n",
    "if False:\n",
    "    for k in range(5, len(top_features) + 1):\n",
    "        top_k_features = top_features[:k]\n",
    "        lr_k = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=3003)\n",
    "        lr_k.fit(x_train[top_k_features], y_train)\n",
    "        y_pred = lr_k.predict(x_test[top_k_features])\n",
    "        y_pred_proba = lr_k.predict_proba(x_test[top_k_features])[:, 1]\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='binary')\n",
    "        prec = precision_score(y_test, y_pred)\n",
    "        rec = recall_score(y_test, y_pred)\n",
    "        roc = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(f\"Top {k} Features -> F1 Score: {f1:.4f}\")\n",
    "\n",
    "top_k_features = top_features[:6]\n",
    "lr_top10 = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=3003)\n",
    "lr_top10.fit(x_train[top_k_features], y_train)\n",
    "y_pred_top10 = lr_top10.predict(x_test[top_k_features])\n",
    "y_pred_top10_proba = lr_top10.predict_proba(x_test[top_k_features])[:, 1]\n",
    "modelResults(\n",
    "    \"LR (Top 10 Features)\",\n",
    "    accuracy_score(y_test, y_pred_top10),\n",
    "    f1_score(y_test, y_pred_top10),\n",
    "    precision_score(y_test, y_pred_top10),\n",
    "    recall_score(y_test, y_pred_top10),\n",
    "    roc_auc_score(y_test, y_pred_top10_proba),\n",
    "    roc_curve(y_test, y_pred_top10_proba),\n",
    "    confusion_matrix(y_test, y_pred_top10, normalize='true')\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Remove features based on correlation"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "corr_matrix = x_train.corr().abs()\n",
    "# Select only the upper triangle of the correlation matrix. k=1 excludes the diagonal (self-correlation=1.0) so we don't accidentally delete every feature and ensuring we check each pair (A vs B) only once and ignore mirror duplicates (B vs A).\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "if False:\n",
    "    for threshold in [0.6, 0.7, 0.8, 0.85, 0.9, 0.95, 0.99]:\n",
    "        to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "        features_keep = [f for f in x_train.columns if f not in to_drop]\n",
    "        lr_corr = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=3003)\n",
    "        lr_corr.fit(x_train[features_keep], y_train)\n",
    "        y_pred = lr_corr.predict_proba(x_test[features_keep])\n",
    "        y_pred_cm = lr_corr.predict(x_test[features_keep])\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred_cm, average='binary')\n",
    "        rec = recall_score(y_test, y_pred_cm)\n",
    "        acc = accuracy_score(y_test, y_pred_cm)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_cm)\n",
    "        print(f\"Thresh {threshold} -> Dropped {len(to_drop)} features. F1: {f1:.4f} (ROC-AUC: {roc_auc:.4f})\")\n",
    "\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\n",
    "features_keep = [f for f in x_train.columns if f not in to_drop]\n",
    "lr_corr = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=3003)\n",
    "lr_corr.fit(x_train[features_keep], y_train)\n",
    "y_pred_proba = lr_corr.predict_proba(x_test[features_keep])\n",
    "y_pred_cm = lr_corr.predict(x_test[features_keep])\n",
    "\n",
    "modelResults(\n",
    "    f\"LR_Corr (> {0.8})\",\n",
    "    accuracy_score(y_test, y_pred_cm), f1_score(y_test, y_pred_cm),\n",
    "    precision_score(y_test, y_pred_cm), recall_score(y_test, y_pred_cm),\n",
    "    roc_auc_score(y_test, y_pred_cm), roc_curve(y_test, y_pred_cm),\n",
    "    confusion_matrix(y_test, y_pred_cm, normalize='true')\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Adding features"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Normalising and computing new features"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "#Going back to basics, the currently used x_train and x_test gave ValueErrors as negative values for Log\n",
    "\n",
    "raw_cols = [c for c in hrv_train_with_labels.columns if c.startswith(\"HRV_\")]\n",
    "raw_train = hrv_train_with_labels[raw_cols].copy()\n",
    "raw_test = hrv_test_clean[raw_cols].copy()\n",
    "\n",
    "raw_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "raw_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "imputer_eng = SimpleImputer(strategy=\"median\")\n",
    "raw_train_imp = pd.DataFrame(imputer_eng.fit_transform(raw_train), columns=raw_cols)\n",
    "raw_test_imp = pd.DataFrame(imputer_eng.transform(raw_test), columns=raw_cols)\n",
    "\n",
    "skewness = raw_train_imp.skew().sort_values(ascending=False)\n",
    "skewed_cols = skewness[abs(skewness) > 1.0].index.tolist()\n",
    "\n",
    "new_features_train = pd.DataFrame(index=raw_train_imp.index)\n",
    "new_features_test = pd.DataFrame(index=raw_test_imp.index)\n",
    "\n",
    "#1. Log Transforms\n",
    "for col in skewed_cols:\n",
    "    # +1e-6 avoids log(0)\n",
    "    new_features_train[f'Log_{col}'] = np.log(raw_train_imp[col] + 1e-6)\n",
    "    new_features_test[f'Log_{col}'] = np.log(raw_test_imp[col] + 1e-6)\n",
    "\n",
    "#2. 2. Coefficient of Variation (CV) computation:\n",
    "if 'HRV_SDNN' in raw_train_imp.columns and 'HRV_MeanNN' in raw_train_imp.columns:\n",
    "    new_features_train['CV_SDNN'] = raw_train_imp['HRV_SDNN'] / (raw_train_imp['HRV_MeanNN'] + 1e-6)\n",
    "    new_features_test['CV_SDNN'] = raw_test_imp['HRV_SDNN'] / (raw_test_imp['HRV_MeanNN'] + 1e-6)\n",
    "\n",
    "# 3. Chaos Index (Amplifies the \"irregularly irregular\" signal specific to AF.):\n",
    "entropy_col = 'HRV_ApEn' if 'HRV_ApEn' in raw_train_imp.columns else 'HRV_SampEn'\n",
    "if 'HRV_RMSSD' in raw_train_imp.columns and entropy_col in raw_train_imp.columns:\n",
    "    new_features_train['Chaos_Index'] = raw_train_imp['HRV_RMSSD'] * raw_train_imp[entropy_col]\n",
    "    new_features_test['Chaos_Index'] = raw_test_imp['HRV_RMSSD'] * raw_test_imp[entropy_col]\n",
    "\n",
    "new_features_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "new_features_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "imputer_new = SimpleImputer(strategy=\"median\")\n",
    "new_train_clean = pd.DataFrame(imputer_new.fit_transform(new_features_train), columns=new_features_train.columns)\n",
    "new_test_clean = pd.DataFrame(imputer_new.transform(new_features_test), columns=new_features_test.columns)\n",
    "\n",
    "scaler_eng = RobustScaler()\n",
    "new_train_scaled = pd.DataFrame(scaler_eng.fit_transform(new_train_clean), columns=new_features_train.columns)\n",
    "new_test_scaled = pd.DataFrame(scaler_eng.transform(new_test_clean), columns=new_features_test.columns)\n",
    "\n",
    "x_train_added = pd.concat([x_train.reset_index(drop=True), new_train_scaled.reset_index(drop=True)], axis=1)\n",
    "x_test_added = pd.concat([x_test.reset_index(drop=True), new_test_scaled.reset_index(drop=True)], axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### \"Use Everything\" Model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lr_aug = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=3003)\n",
    "lr_aug.fit(x_train_added, y_train)\n",
    "y_pred_aug_proba = lr_aug.predict_proba(x_test_added)[:, 1]\n",
    "y_pred_aug = lr_aug.predict(x_test_added)\n",
    "\n",
    "f1_aug = f1_score(y_test, y_pred_aug)\n",
    "print(f\"Augmented F1: {f1_aug:.4f}\")\n",
    "\n",
    "modelResults(\n",
    "    \"LR_Augmented (All Features)\",\n",
    "    accuracy_score(y_test, y_pred_aug), f1_aug,\n",
    "    precision_score(y_test, y_pred_aug), recall_score(y_test, y_pred_aug),\n",
    "    roc_auc_score(y_test, y_pred_aug_proba), roc_curve(y_test, y_pred_aug_proba),\n",
    "    confusion_matrix(y_test, y_pred_aug, normalize='true')\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### \"Drop Parents\" Model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "parents_to_drop = set()\n",
    "\n",
    "# Dropping Skewed columns (We have Log_RMSSD, so drop RMSSD)\n",
    "parents_to_drop.update(skewed_cols)\n",
    "\n",
    "# Dropping Ratio Parents (We have CV_SDNN, so drop SDNN and MeanNN)\n",
    "if 'CV_SDNN' in new_features_train.columns:\n",
    "    parents_to_drop.update(['HRV_SDNN', 'HRV_MeanNN'])\n",
    "\n",
    "# Dropping Interaction Parents (We have Chaos, so drop RMSSD and Entropy)\n",
    "if 'Chaos_Index' in new_features_train.columns:\n",
    "    parents_to_drop.update(['HRV_RMSSD', entropy_col])\n",
    "\n",
    "features_to_keep = [f for f in x_train_added.columns if f not in parents_to_drop]\n",
    "\n",
    "lr_rep = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=3003)\n",
    "lr_rep.fit(x_train_added[features_to_keep], y_train)\n",
    "y_pred_rep_proba = lr_rep.predict_proba(x_test_added[features_to_keep])[:, 1]\n",
    "y_pred_rep = lr_rep.predict(x_test_added[features_to_keep])\n",
    "\n",
    "f1_rep = f1_score(y_test, y_pred_rep)\n",
    "print(f\"Replacement F1: {f1_rep:.4f}\")\n",
    "\n",
    "modelResults(\n",
    "    \"LR_Replacement (Drop Parents)\",\n",
    "    accuracy_score(y_test, y_pred_rep), f1_rep,\n",
    "    precision_score(y_test, y_pred_rep), recall_score(y_test, y_pred_rep),\n",
    "    roc_auc_score(y_test, y_pred_rep_proba), roc_curve(y_test, y_pred_rep_proba),\n",
    "    confusion_matrix(y_test, y_pred_rep, normalize='true')\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Random Forest"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "feature_names = hrv_train_with_labels.columns",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for n in range(14):\n",
    "    n = n + 1\n",
    "    model_RF = RandomForestClassifier(max_depth=n, random_state=3003)\n",
    "    model_RF.fit(x_train, y_train)\n",
    "    y_pred_proba = model_RF.predict_proba(x_test)[:, 1]\n",
    "    y_pred = model_RF.predict(x_test)\n",
    "\n",
    "    modelResults(model_RF, accuracy, f1_score(y_test, y_pred), precision_score(y_test, y_pred),\n",
    "                 recall_score(y_test, y_pred), roc_auc_score(y_test, y_pred_proba), roc_curve(y_test, y_pred_proba), cm)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "_ = tree.plot_tree(model_RF.estimators_[0],\n",
    "                   feature_names=feature_names,\n",
    "                   class_names=['Normal rythm', 'Atrial fibrillation'],\n",
    "                   filled=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Neighbours Classifiers\n",
    "### K Neighbours"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for n in range(15):\n",
    "    n = n + 1\n",
    "    model_KNN = KNeighborsClassifier(n_neighbors=n)\n",
    "    model_KNN.fit(x_train, y_train)\n",
    "\n",
    "    y_pred_proba = model_KNN.predict_proba(x_test)[:, 1]\n",
    "    y_pred = model_KNN.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    roc_cur = roc_curve(y_test, y_pred_proba)\n",
    "    cm = confusion_matrix(y_true=y_test, y_pred=y_pred, normalize='true')\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model_KNN.classes_)\n",
    "    disp.plot()\n",
    "\n",
    "    model_KNN_n = str(model_KNN) + str(f\" n={n}\")\n",
    "    modelResults(model_KNN_n, accuracy, f1, precision, recall, roc_auc, roc_cur, cm)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Radius Neighbours"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for radius in [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 5.0, 10.0]:\n",
    "    model_RNC = RadiusNeighborsClassifier(radius=radius, outlier_label='most_frequent')\n",
    "    model_RNC.fit(x_train, y_train)\n",
    "\n",
    "    y_pred_proba = model_RNC.predict_proba(x_test)[:, 1]\n",
    "    y_pred = model_RNC.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    roc_cur = roc_curve(y_test, y_pred_proba)\n",
    "    cm = confusion_matrix(y_true=y_test, y_pred=y_pred, normalize='true')\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model_RNC.classes_)\n",
    "    disp.plot()\n",
    "\n",
    "    modelResults(model_RNC, accuracy, f1, precision, recall, roc_auc, roc_cur, cm)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Nearest Centroid Classifier"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "model_NCC = NearestCentroid()\n",
    "model_NCC.fit(x_train, y_train)\n",
    "\n",
    "y_pred_proba = model_NCC.predict_proba(x_test)[:, 1]\n",
    "y_pred = model_NCC.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "roc_cur = roc_curve(y_test, y_pred_proba)\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred, normalize='true')\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model_NCC.classes_)\n",
    "disp.plot()\n",
    "\n",
    "modelResults(model_NCC, accuracy, f1, precision, recall, roc_auc, roc_cur, cm)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "##TODO: NCC",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Multi-layer Perceptron Classifier"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scaler_mlp = StandardScaler()\n",
    "x_train_scaled = scaler_mlp.fit_transform(x_train)\n",
    "x_test_scaled = scaler_mlp.transform(x_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "##TODO: other solvers? other hidden layer sizes? other max_iter?",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_MLP = MLPClassifier(solver=\"lbfgs\", hidden_layer_sizes=(100, 50), max_iter=1000, random_state=3003)\n",
    "model_MLP.fit(x_train_scaled, y_train)\n",
    "\n",
    "y_pred_proba = model_MLP.predict_proba(x_test_scaled)[:, 1]\n",
    "y_pred = model_MLP.predict(x_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "roc_cur = roc_curve(y_test, y_pred_proba)\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred, normalize='true')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model_MLP.classes_)\n",
    "disp.plot()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "modelResults(model_MLP, accuracy, f1, precision, recall, roc_auc, roc_cur, cm)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Gradient Boosting Classifier"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_GBC = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=3003\n",
    ")\n",
    "\n",
    "model_GBC.fit(x_train, y_train)\n",
    "\n",
    "y_pred_proba = model_GBC.predict_proba(x_test)[:, 1]\n",
    "y_pred = model_GBC.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "roc_cur = roc_curve(y_test, y_pred_proba)\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred, normalize='true')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model_GBC.classes_)\n",
    "disp.plot()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "modelResults(model_GBC, accuracy, f1, precision, recall, roc_auc, roc_cur, cm)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## AdaBoost Classifier"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#TODO: implement testing\n",
    "for n in [50, 100, 200, 300, 400, 500, 1000]:\n",
    "    clf = AdaBoostClassifier(n_estimators=n)\n",
    "    scores = cross_val_score(clf, x_train, y_train, cv=5)\n",
    "    print(scores.mean())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Soft voting classifier"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voters = [\n",
    "    (\"lr\", LogisticRegression(multi_class='auto', max_iter=1000, class_weight='balanced', random_state=3003)),\n",
    "    (\"rf\", RandomForestClassifier(n_estimators=300, max_depth=None, random_state=3003)),\n",
    "    (\"knn\", KNeighborsClassifier(n_neighbors=7))\n",
    "]\n",
    "\n",
    "soft_vote = VotingClassifier(estimators=voters, voting=\"soft\", n_jobs=-1)\n",
    "soft_vote.fit(x_train, y_train)\n",
    "\n",
    "y_pred_proba = soft_vote.predict_proba(x_test)[:, 1]\n",
    "y_pred = soft_vote.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "roc_cur = roc_curve(y_test, y_pred_proba)\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred, normalize='true')\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=soft_vote.classes_)\n",
    "disp.plot()\n",
    "\n",
    "modelResults(soft_vote, accuracy, f1, precision, recall, roc_auc, roc_cur, cm)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Gaussian Processes Classifier"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "## TODO: Gaussian Processes Classifier",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ensure required imports are available; install if missing\n",
    "try:\n",
    "    from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "    from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, DotProduct, WhiteKernel\n",
    "except Exception:\n",
    "    !pip install scikit-learn\n",
    "    from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "    from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, DotProduct, WhiteKernel"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if False:  # Warning, long\n",
    "    # Define a kernel suitable for scaled features and binary classification\n",
    "    # Start with signal variance * RBF(length-scale) + small WhiteKernel for numerical stability\n",
    "    kernel = C(1.0, (1e-3, 1e3)) * RBF(length_scale=1.0, length_scale_bounds=(1e-3, 1e3)) + WhiteKernel(\n",
    "        noise_level=1e-3, noise_level_bounds=(1e-6, 1e-1))\n",
    "\n",
    "    gpc = GaussianProcessClassifier(kernel=kernel, random_state=3003, n_restarts_optimizer=2, max_iter_predict=200)\n",
    "\n",
    "    gpc.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = gpc.predict(x_test)\n",
    "    y_prob = gpc.predict_proba(x_test)[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    roc_cur = roc_curve(y_test, y_prob)\n",
    "    cm = confusion_matrix(y_true=y_test, y_pred=y_pred, normalize='true')\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gpc.classes_)\n",
    "    disp.plot()\n",
    "\n",
    "    modelResults(gpc, accuracy, f1, precision, recall, roc_auc, roc_cur, cm)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Gradient-boosted trees"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve, \\\n",
    "    confusion_matrix, classification_report\n",
    "\n",
    "gbc = GradientBoostingClassifier(random_state=3003)\n",
    "gbc.fit(x_train, y_train)\n",
    "\n",
    "y_pred = gbc.predict(x_test)\n",
    "y_pred_proba = gbc.predict_proba(x_test)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "roc_cur = roc_curve(y_test, y_pred_proba)\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred, normalize='true')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gbc.classes_)\n",
    "disp.plot()\n",
    "\n",
    "modelResults(gbc, accuracy, f1, precision, recall, roc_auc, roc_cur, cm)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 400],\n",
    "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "    \"max_depth\": [2, 3, 4],\n",
    "    \"subsample\": [0.8, 1.0]\n",
    "}\n",
    "\n",
    "gbc_base = GradientBoostingClassifier(random_state=3003)\n",
    "cv = GridSearchCV(gbc_base, param_grid, scoring=\"f1\", cv=5, n_jobs=-1, refit=True)\n",
    "cv.fit(x_train, y_train)\n",
    "\n",
    "best_gbc = cv.best_estimator_\n",
    "print(\"Best params:\", cv.best_params_)\n",
    "\n",
    "y_pred = best_gbc.predict(x_test)\n",
    "y_pred_proba = best_gbc.predict_proba(x_test)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "roc_cur = roc_curve(y_test, y_pred_proba)\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred, normalize='true')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_gbc.classes_)\n",
    "disp.plot()\n",
    "\n",
    "modelResults(best_gbc, accuracy, f1, precision, recall, roc_auc, roc_cur, cm)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "## TODO: Gradient-boosted trees",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Semi-supervised learning?"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "## TODO: Semi-supervised learning?",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model evaluation\n",
    "## Quick conclusion"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "original_size = resultsTable.shape[0]\n",
    "resultsTable = resultsTable.drop_duplicates(subset=['Model', 'Accuracy', 'F1 Score', 'Precision', 'Recall', 'ROC_AUC'])\n",
    "print(f\"Dropped {resultsTable.shape[0] - original_size} duplicate rows\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "resultsTable",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_model = resultsTable.loc[resultsTable['F1 Score'].idxmax()]\n",
    "\n",
    "print(f\"The model with the highest F1 score was {best_model['Model']} with an F1 score of {best_model['F1 Score']:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Graphs of numerical metrics\n",
    "### Logarithmic scale"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#TODO: this is failing out of nowhere and I have no idea how to fix it TwT\n",
    "if False:\n",
    "    numeric_metrics = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'ROC_AUC']\n",
    "\n",
    "    model_labels = [str(model).split('(')[0] for model in resultsTable['Model']]\n",
    "\n",
    "    fig, axes = plt.subplots(len(numeric_metrics), 1, figsize=(10, len(numeric_metrics) * 8), dpi=100)\n",
    "\n",
    "    for i, col in enumerate(numeric_metrics):\n",
    "        bars = axes[i].bar(range(len(resultsTable)), resultsTable[col])\n",
    "        axes[i].set_xticks(range(len(resultsTable)))\n",
    "        axes[i].set_xticklabels(model_labels, rotation=45, ha='right')\n",
    "        axes[i].set_ylabel(col)\n",
    "        axes[i].set_title(f'{col} by Model')\n",
    "        axes[i].set_yscale('log')\n",
    "        axes[i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "        for j, bar in enumerate(bars):\n",
    "            height = bar.get_height()\n",
    "            axes[i].text(bar.get_x() + bar.get_width() / 2., height,\n",
    "                         f'{resultsTable[col].iloc[j]:.3f}',\n",
    "                         ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numeric_metrics = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'ROC_AUC']\n",
    "\n",
    "model_labels = [str(model).split('(')[0] for model in resultsTable['Model']]\n",
    "\n",
    "fig, axes = plt.subplots(len(numeric_metrics), 1, figsize=(10, len(numeric_metrics) * 8))\n",
    "\n",
    "for i, col in enumerate(numeric_metrics):\n",
    "    bars = axes[i].bar(range(len(resultsTable)), resultsTable[col])\n",
    "    axes[i].set_xticks(range(len(resultsTable)))\n",
    "    axes[i].set_xticklabels(model_labels, rotation=45, ha='right')\n",
    "    axes[i].set_ylabel(col)\n",
    "    axes[i].set_title(f'{col} by Model')\n",
    "    axes[i].set_ylim(top=1)\n",
    "    axes[i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "    for j, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        axes[i].text(bar.get_x() + bar.get_width() / 2., height,\n",
    "                     f'{resultsTable[col].iloc[j]:.3f}',\n",
    "                     ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ROC Curves"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for idx, row in resultsTable.iterrows():\n",
    "    model_name = str(row['Model']).split('(')[0]\n",
    "    fpr, tpr, thresholds = row['ROC']\n",
    "    roc_auc = row['ROC_AUC']\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{model_name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier (AUC = 0.500)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curves - Model Comparison', fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=15)\n",
    "plt.grid(alpha=1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Data-Witches",
   "name": "data-witches",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
