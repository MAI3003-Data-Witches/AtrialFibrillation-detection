{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc59ac1af6732554",
   "metadata": {},
   "source": [
    "# **Data Witches**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b45f2690fd28b7",
   "metadata": {},
   "source": [
    "| **Name**         | **Student ID** |\n",
    "|------------------|----------------|\n",
    "| Claessen, VVHJAE | i6339543       |\n",
    "| Ovsiannikova, AM | i6365923       |\n",
    "| Pubben, J        | i6276134       |\n",
    "| Roca Cugat, M    | i6351071       |\n",
    "| Záboj, J         | i6337952       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aece5caa34473",
   "metadata": {},
   "source": [
    "# **Logbook**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28fc7429c87cc80",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "Let's ensure we all use the same names for all components.\n",
    "\n",
    "| **Variable**                 | **Name**                                      |\n",
    "|------------------------------|-----------------------------------------------|\n",
    "| Raw ECG dataframe            | df                                            |\n",
    "| Label dataframe              | df_labels                                     |\n",
    "| HRV features (train)         | hrv_train                                     |\n",
    "| HRV features (test)          | hrv_test                                      |\n",
    "| HRV extraction type          | FULL (nk.hrv — time + freq + nonlinear + RSA) |\n",
    "| Clean HRV dataframe (train)  | hrv_train_clean                               |\n",
    "| Clean HRV dataframe (test)   | hrv_test_clean                                |\n",
    "| HRV + labels (train)         | hrv_train_with_labels                         |\n",
    "| Winsorized HRV column        | HRV_MedianNN_winsor                           |\n",
    "| Model feature matrix (train) | X_train                                       |\n",
    "| Model feature matrix (test)  | X_test                                        |\n",
    "| Model target vector (train)  | y_train                                       |\n",
    "| Model target vector (test)   | y_test                                        |\n",
    "\n",
    "\n",
    "| **Function**              | **Description**                                | **Arguments**                                |\n",
    "|---------------------------|------------------------------------------------|----------------------------------------------|\n",
    "| corr_plot_hrv()           | Correlation plot for HRV features              | df, cols=None                                |\n",
    "| distplots_hrv()           | Distribution plots (hist + KDE)                | df, cols=None                                |\n",
    "| boxplots_hrv()            | Boxplots for selected HRV variables            | df, cols                                     |\n",
    "| check_missing_hrv()       | Missingness summary                            | df                                           |\n",
    "| identify_outliers()       | IQR-based outlier detection                    | df, column_name, threshold=1.5               |\n",
    "| model_evaluation()        | Confusion matrix + classification report       | model                                        |\n",
    "| model_desc()              | Accuracy, CV, ROC-AUC, model performance       | model                                        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71e4ef40a858913",
   "metadata": {},
   "source": [
    "# Preface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25be65589590fcb3",
   "metadata": {},
   "source": [
    "## Packages imports"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "try:\n",
    "    print(\"Loading required packages...\")\n",
    "    import sys\n",
    "    import random\n",
    "    import os.path\n",
    "    import warnings\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import neurokit2 as nk\n",
    "    from scipy import stats\n",
    "    import scipy.signal as signal\n",
    "    from scipy.signal import welch\n",
    "    import matplotlib.pyplot as plt\n",
    "    from joblib.testing import xfail\n",
    "    import plotly.graph_objects as go\n",
    "    from colorama import Fore, Back, Style\n",
    "    from plotly.subplots import make_subplots\n",
    "\n",
    "    from sklearn import tree\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.compose import make_column_transformer\n",
    "    from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "    from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RepeatedStratifiedKFold\n",
    "    from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, \\\n",
    "        f1_score, precision_score, recall_score, roc_auc_score, roc_curve, RocCurveDisplay, precision_recall_curve\n",
    "    from sympy import false\n",
    "\n",
    "    print(\"Loading successful!\")\n",
    "except Exception:\n",
    "    print(\"Installing required packages...\")\n",
    "    !pip install -r requirements.txt\n",
    "\n",
    "    print(\"Loading required packages...\")\n",
    "    import sys\n",
    "    import random\n",
    "    import os.path\n",
    "    import warnings\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import neurokit2 as nk\n",
    "    from scipy import stats\n",
    "    import scipy.signal as signal\n",
    "    from scipy.signal import welch\n",
    "    import matplotlib.pyplot as plt\n",
    "    from joblib.testing import xfail\n",
    "    import plotly.graph_objects as go\n",
    "    from colorama import Fore, Back, Style\n",
    "    from plotly.subplots import make_subplots\n",
    "\n",
    "    from sklearn import tree\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.compose import make_column_transformer\n",
    "    from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "    from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RepeatedStratifiedKFold\n",
    "    from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, \\\n",
    "        f1_score, precision_score, recall_score, roc_auc_score, roc_curve, RocCurveDisplay, precision_recall_curve\n",
    "    from sympy import false\n",
    "\n",
    "    print(\"Loading successful!\")"
   ],
   "id": "935982e3a32ed56c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "59e2fb78a188e3b7",
   "metadata": {},
   "source": [
    "## Options settings"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(3003)\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "DATA_PRESENT = os.path.isfile(\"data/Physionet2017Training.tar.xz\")\n",
    "LoadPremadeDataset = True"
   ],
   "id": "819e915fcae8246a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset download",
   "id": "c86b5c3396c77ade"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dataset_location = 'data/Physionet2017TrainingData.csv'",
   "id": "733e8c8745ebdb32",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "322a29c57caf6a30",
   "metadata": {},
   "source": [
    "if not DATA_PRESENT:\n",
    "    !mkdir data\n",
    "    !wget https://github.com/MAI3003-Data-Witches/Data-Witches_Project2/raw/refs/heads/main/data/Physionet2017Training.tar.xz -O data/Physionet2017Training.tar.xz\n",
    "    !tar -xf data/Physionet2017Training.tar.xz -C data\n",
    "else:\n",
    "    print(f\"You already have the dataset downloaded at {dataset_location}, skipping\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8194ca8419d6a2c6",
   "metadata": {},
   "source": [
    "df = pd.read_csv(dataset_location, header=None, index_col=False) * 1000  # Load the dataset already in mV\n",
    "\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d791f19d174d1807",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "## Extract ECG signals and class labels"
   ]
  },
  {
   "cell_type": "code",
   "id": "df6051637427b19c",
   "metadata": {},
   "source": [
    "df_labels = pd.read_csv('data/Physionet2017TrainingLabels.csv', header=None, names=['label'])\n",
    "df_labels['classification'] = df_labels['label'].replace({\"N\": 0, \"A\": 1})\n",
    "df_labels['label'] = df_labels['label'].replace({\"N\": 'Normal Sinus Rhythm', \"A\": 'Atrial Fibrillation'})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ea89a4141e557191",
   "metadata": {},
   "source": [
    "df_labels"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7675a917e497d489",
   "metadata": {},
   "source": [
    "## Dataset splitting"
   ]
  },
  {
   "cell_type": "code",
   "id": "c5fced9de142ddf0",
   "metadata": {},
   "source": [
    "df_labeled = pd.merge(df_labels.drop(columns='label'), df, left_on='classification', right_index=True)\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    df.index,\n",
    "    test_size=0.2,\n",
    "    stratify=df_labels[\"label\"],\n",
    "    random_state=3003\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(train_idx))\n",
    "print(\"Test size:\", len(test_idx))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3828b0d61f36b49e",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "## Dataset characteristics"
   ]
  },
  {
   "cell_type": "code",
   "id": "84bd5e353e92a4f",
   "metadata": {},
   "source": [
    "num_ecgs = len(df)  # Number of ECGs\n",
    "\n",
    "num_samples = df.shape[1]  # Number of samples per ECG\n",
    "\n",
    "sampling_frequency = 300  #Hz\n",
    "duration = num_samples / sampling_frequency  # Duration of each ECG\n",
    "\n",
    "class_distribution = df_labels['label'].value_counts()  # Distribution over classes\n",
    "\n",
    "print(f\"Number of ECGs: {num_ecgs}\")\n",
    "print(f\"Number of samples per ECG: {num_samples}\")\n",
    "print(f\"Duration of each ECG: {duration} seconds\")\n",
    "print(f\"\\nClass Distribution:\\n{class_distribution}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "29c63dc163550429",
   "metadata": {},
   "source": [
    "# Indices per class (based on df_labels)\n",
    "sinus_indices = df_labels[df_labels[\"label\"] == \"Normal Sinus Rhythm\"].index.tolist()\n",
    "af_indices = df_labels[df_labels[\"label\"] == \"Atrial Fibrillation\"].index.tolist()\n",
    "\n",
    "example_sinus_idx = random.choice(sinus_indices)\n",
    "example_af_idx = random.choice(af_indices)\n",
    "\n",
    "ecg_sinus_raw = df.iloc[example_sinus_idx].astype(float).values\n",
    "ecg_af_raw = df.iloc[example_af_idx].astype(float).values\n",
    "\n",
    "time = np.arange(0, len(ecg_sinus_raw)) / sampling_frequency"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b6b534d7e483039f",
   "metadata": {},
   "source": [
    "# Summary statistics for each ECG\n",
    "summary_stats = df.describe().T\n",
    "summary_stats = pd.concat([summary_stats, df_labels], axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fbfb192ded15f5a0",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27b648ef4075e99",
   "metadata": {},
   "source": [
    "## ECG feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "id": "fd97ff94c0210770",
   "metadata": {},
   "source": [
    "# Select an ECG in Normal Sinus Rhythm and one in AF and process them\n",
    "selected_sinus_indices = random.sample(sinus_indices, 1)\n",
    "selected_af_indices = random.sample(af_indices, 1)\n",
    "\n",
    "ecg_NSR = df.iloc[selected_sinus_indices[0]].astype(float)\n",
    "signals_NSR, info_NSR = nk.ecg_process(ecg_NSR, sampling_rate=sampling_frequency)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 4]\n",
    "nk.ecg_plot(signals_NSR, info_NSR)\n",
    "\n",
    "ecg_AF = df.iloc[selected_af_indices[0]].astype(float)\n",
    "signals_AF, info_AF = nk.ecg_process(ecg_AF, sampling_rate=sampling_frequency)\n",
    "\n",
    "nk.ecg_plot(signals_AF, info_AF)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8f74f5d0762fab8b",
   "metadata": {},
   "source": [
    "#### R-peaks**"
   ]
  },
  {
   "cell_type": "code",
   "id": "b5cd75b1c1a167e8",
   "metadata": {},
   "source": [
    "# Find R-peaks\n",
    "peaks_NSR, info_NSR = nk.ecg_peaks(ecg_NSR, sampling_rate=sampling_frequency, correct_artifacts=True, show=True)\n",
    "peaks_AF, info_AF = nk.ecg_peaks(ecg_AF, sampling_rate=sampling_frequency, correct_artifacts=True, show=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "af2f35def467d115",
   "metadata": {},
   "source": [
    "#### Time-domain features"
   ]
  },
  {
   "cell_type": "code",
   "id": "abdd28449f7935bd",
   "metadata": {},
   "source": [
    "# Time domain features NSR\n",
    "hrv_time_NSR = nk.hrv_time(peaks_NSR, sampling_rate=sampling_frequency, show=True)\n",
    "hrv_time_NSR"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9fa3719508ed858d",
   "metadata": {},
   "source": [
    "# Time domain features AF\n",
    "hrv_time_AF = nk.hrv_time(peaks_AF, sampling_rate=sampling_frequency, show=True)\n",
    "hrv_time_AF"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "58c989c0300881b3",
   "metadata": {},
   "source": [
    "### FULL HRV feature extraction for all ECGs (TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "id": "66181ce776e08427",
   "metadata": {},
   "source": [
    "#Getting all the ECG readouts so we can extract P-wave information\n",
    "\n",
    "def get_ECG_readout():\n",
    "    test_run = 0\n",
    "    ecg_full = pd.DataFrame()  # Initialize an empty DataFrame\n",
    "\n",
    "    for i in tqdm(train_idx):\n",
    "\n",
    "        ecg = df.iloc[i].astype(float)\n",
    "        signals, info = nk.ecg_process(ecg, sampling_rate=sampling_frequency)\n",
    "\n",
    "        # Assign the current ecg_index to the signals DataFrame before concatenation\n",
    "        signals[\"ecg_index\"] = i\n",
    "\n",
    "        ecg_full = pd.concat([ecg_full, signals], ignore_index=True)\n",
    "\n",
    "        #test_run += 1\n",
    "\n",
    "        if test_run == 10:\n",
    "            break  # Stop after 10 iterations for the example\n",
    "\n",
    "    return ecg_full"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if LoadPremadeDataset == False:\n",
    "    ecg_full = get_ECG_readout()"
   ],
   "id": "70ea9b4db99ae781",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_ECG_metrics(ecg_full):\n",
    "    ecg_metrics_list = []\n",
    "\n",
    "    for i in tqdm(train_idx[:]):\n",
    "        mean_quality = ecg_full.loc[ecg_full.ecg_index == i]['ECG_Quality'].mean()\n",
    "        mean_pwave_amplitude = ecg_full.loc[(ecg_full.ecg_index == i) & (ecg_full['ECG_P_Peaks'] == 1)][\n",
    "            'ECG_Clean'].mean()  #You could consider taking sqrt, mean and then **2\n",
    "        #(more robust) to outliers\n",
    "        stdev_pwave = ecg_full.loc[(ecg_full.ecg_index == i) & (ecg_full['ECG_P_Peaks'] == 1)]['ECG_Quality'].std()\n",
    "        #Perhaps I could add something about irregularly irregular rhythm, but it's (really) difficult mathematically\n",
    "        ecg_metrics_list.append({\n",
    "            'Mean_Quality': mean_quality,\n",
    "            'Mean_PWave_Amplitude': mean_pwave_amplitude,\n",
    "            'STDEV_Pwave': stdev_pwave,\n",
    "            'ecg_index': i\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(ecg_metrics_list)"
   ],
   "id": "bc3570a7d46b4f4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if LoadPremadeDataset == False:\n",
    "    ecg_metrics = get_ECG_metrics(ecg_full)"
   ],
   "id": "34641567b50a2144",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if LoadPremadeDataset == False:\n",
    "    #FULL HRV feature extraction for all ECGs (TRAIN)\n",
    "\n",
    "    hrv_features_train = []\n",
    "\n",
    "    for i in tqdm(train_idx, desc=\"HRV (ALL FEATURES): TRAIN SET\"):\n",
    "        # Grab raw ECG\n",
    "        ecg = df.iloc[i].astype(float).values\n",
    "\n",
    "        try:\n",
    "            # 1. Clean ECG\n",
    "            ecg_clean = nk.ecg_clean(ecg, sampling_rate=sampling_frequency)\n",
    "\n",
    "            # 2. Detect R-peaks\n",
    "            peaks, _ = nk.ecg_peaks(\n",
    "                ecg_clean,\n",
    "                sampling_rate=sampling_frequency,\n",
    "                correct_artifacts=True\n",
    "            )\n",
    "\n",
    "            # 3. Compute FULL HRV feature set\n",
    "            hrv_full = nk.hrv(\n",
    "                peaks,\n",
    "                sampling_rate=sampling_frequency,\n",
    "                show=False\n",
    "            )\n",
    "\n",
    "            # Ensure row is a proper 1-row DataFrame and add ecg_index\n",
    "            hrv_full = hrv_full.copy()\n",
    "            hrv_full[\"ecg_index\"] = i\n",
    "\n",
    "            hrv_features_train.append(hrv_full)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing TRAIN ECG {i}: {e}\")\n",
    "\n",
    "            if hrv_features_train:\n",
    "                empty = pd.DataFrame(\n",
    "                    [np.nan] * hrv_features_train[0].shape[1],\n",
    "                    index=hrv_features_train[0].columns\n",
    "                ).T\n",
    "                empty[\"ecg_index\"] = i\n",
    "                hrv_features_train.append(empty)\n",
    "\n",
    "    # Combine to single DataFrame\n",
    "    hrv_train = pd.concat(hrv_features_train, ignore_index=True)\n",
    "\n",
    "    print(\"hrv_train shape:\", hrv_train.shape)\n",
    "    hrv_train.head()"
   ],
   "id": "ffe3c788bcbafcb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if LoadPremadeDataset == False:\n",
    "    # Merge our new dataframe with our extra variables\n",
    "    hrv_train = pd.merge(hrv_train, ecg_metrics, on='ecg_index', how='left')\n",
    "    hrv_train.head()"
   ],
   "id": "246f651e44e4a524",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if LoadPremadeDataset == False:\n",
    "    # Remove all columns from the dataframe that contain more than 50% NaN\n",
    "    threshold = 0.5\n",
    "    hrv_train_clean = hrv_train.dropna(thresh=len(hrv_train) * threshold, axis=1)\n",
    "\n",
    "    # Remove all rows that are all NaN\n",
    "    hrv_train_clean = hrv_train_clean.dropna(how='all')\n",
    "\n",
    "    hrv_train_clean.to_csv(\"data/hrv_train.csv\", index=False)\n",
    "    hrv_train_clean.head()"
   ],
   "id": "45d9970684e66736",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3d45a439ee1629c2",
   "metadata": {},
   "source": [
    "### FULL HRV feature extraction for all ECGs (TEST)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if LoadPremadeDataset == False:\n",
    "    hrv_features_test = []\n",
    "\n",
    "    for i in tqdm(test_idx, desc=\"HRV (ALL FEATURES): TEST SET\"):\n",
    "        ecg = df.iloc[i].astype(float).values\n",
    "\n",
    "        try:\n",
    "            # 1. Clean ECG\n",
    "            ecg_clean = nk.ecg_clean(ecg, sampling_rate=sampling_frequency)\n",
    "\n",
    "            # 2. Detect R-peaks\n",
    "            peaks, _ = nk.ecg_peaks(\n",
    "                ecg_clean,\n",
    "                sampling_rate=sampling_frequency,\n",
    "                correct_artifacts=True\n",
    "            )\n",
    "\n",
    "            # 3. Compute FULL HRV feature set\n",
    "            hrv_full = nk.hrv(\n",
    "                peaks,\n",
    "                sampling_rate=sampling_frequency,\n",
    "                show=False\n",
    "            )\n",
    "\n",
    "            # Same as TRAIN: keep as 1-row DataFrame, add index\n",
    "            hrv_full = hrv_full.copy()\n",
    "            hrv_full[\"ecg_index\"] = i\n",
    "\n",
    "            hrv_features_test.append(hrv_full)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing TEST ECG {i}: {e}\")\n",
    "\n",
    "            if hrv_features_test:\n",
    "                empty = pd.DataFrame(\n",
    "                    [np.nan] * hrv_features_test[0].shape[1],\n",
    "                    index=hrv_features_test[0].columns\n",
    "                ).T\n",
    "                empty[\"ecg_index\"] = i\n",
    "                hrv_features_test.append(empty)\n",
    "\n",
    "    hrv_test = pd.concat(hrv_features_test, ignore_index=True)\n",
    "\n",
    "    print(\"hrv_test shape:\", hrv_test.shape)\n",
    "    hrv_test.head()"
   ],
   "id": "a62cc3a091741aa9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if LoadPremadeDataset == False:\n",
    "    # Merge our new dataframe with our extra variables\n",
    "    hrv_test = pd.merge(hrv_test, ecg_metrics, on='ecg_index', how='left')\n",
    "    hrv_test.head()"
   ],
   "id": "9c6398a8f3c290bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if LoadPremadeDataset == False:\n",
    "    # Remove all columns from the dataframe that contain more than 50% NaN\n",
    "    threshold = 0.5\n",
    "    hrv_test_clean = hrv_test.dropna(thresh=len(hrv_test) * threshold, axis=1)\n",
    "\n",
    "    # Remove all rows that are all NaN\n",
    "    hrv_test_clean = hrv_test_clean.dropna(how='all')\n",
    "\n",
    "    hrv_test_clean.head()\n",
    "\n",
    "    hrv_test.to_csv(\"data/hrv_test.csv\", index=False)"
   ],
   "id": "b1f2417bae20eeac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# If you don't want to wait that long",
   "id": "665248a1390150b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if LoadPremadeDataset == True:\n",
    "    hrv_test_clean = pd.read_csv(\"data/hrv_test.csv\")\n",
    "    hrv_train_clean= pd.read_csv(\"data/hrv_train.csv\")"
   ],
   "id": "7e201ef017dbfd5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Feature exploration",
   "id": "75c6622e3b55e0cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Merge the HRV data with the rhythm labels\n",
    "hrv_train_with_labels = pd.merge(\n",
    "    hrv_train_clean, df_labels, left_on='ecg_index', right_index=True\n",
    ").reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "selectedMetric = 'HRV_MedianNN'\n",
    "rhythms = hrv_train_with_labels['label'].unique()\n",
    "for rhythm in rhythms:\n",
    "    subset = hrv_train_with_labels[hrv_train_with_labels['label'] == rhythm]\n",
    "    plt.hist(subset[selectedMetric], alpha=0.7, label=rhythm, bins='auto')\n",
    "\n",
    "plt.xlabel(selectedMetric)\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution by Rhythm')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "a98d942ff4c964dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "84011cdd339fb0a2",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd7156d74494298",
   "metadata": {},
   "source": [
    "## Missingness"
   ]
  },
  {
   "cell_type": "code",
   "id": "85661f71d7d18bdc",
   "metadata": {},
   "source": [
    "def check_missing_hrv(df):\n",
    "    \"\"\"\n",
    "    Summarize missingness across HRV features.\n",
    "    \"\"\"\n",
    "    missing = df.isna().sum()\n",
    "    out = pd.DataFrame({\n",
    "        \"feature\": df.columns,\n",
    "        \"missing_n\": missing,\n",
    "        \"missing_%\": (missing / len(df)) * 100\n",
    "    })\n",
    "    display(out.sort_values(\"missing_%\", ascending=False))\n",
    "    return out"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d610d38ba4561404",
   "metadata": {},
   "source": [
    "check_missing_hrv(hrv_train_clean)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a00714e3ee6f401e",
   "metadata": {},
   "source": [
    "## Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "id": "dc5d9abcf1bb4e03",
   "metadata": {},
   "source": [
    "# Function to identify outliers in the data\n",
    "def identify_outliers(df, column_name, threshold=1.5):\n",
    "    # Calculate Q1, Q3, and IQR\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define outlier bounds\n",
    "    lower_bound = Q1 - threshold * IQR\n",
    "    upper_bound = Q3 + threshold * IQR\n",
    "\n",
    "    # Identify outliers\n",
    "    row_indices = df[(df[column_name] < lower_bound) | (df[column_name] > upper_bound)].index.tolist()\n",
    "    outlier_values = df.loc[row_indices, column_name].tolist()\n",
    "\n",
    "    return row_indices, outlier_values, lower_bound, upper_bound"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7fa9774d200f7932",
   "metadata": {},
   "source": [
    "# Outlier detection ONLY ON TRAIN\n",
    "\n",
    "# Merge labels with TRAIN features (cleaned hrv_train)\n",
    "hrv_train_with_labels = pd.merge(\n",
    "    hrv_train_clean, df_labels, left_on=\"ecg_index\", right_index=True\n",
    ")\n",
    "\n",
    "# Outlier detection ONLY on TRAIN\n",
    "train_outlier_idx, outlier_values, iqr_lower, iqr_upper = identify_outliers(\n",
    "    hrv_train_with_labels,\n",
    "    \"HRV_MedianNN\",\n",
    "    threshold=1.5\n",
    ")\n",
    "\n",
    "# ecg_index as (int)\n",
    "hrv_train_with_labels[\"ecg_index\"] = hrv_train_with_labels[\"ecg_index\"].astype(int)\n",
    "\n",
    "print(\"Train outliers detected:\", len(train_outlier_idx))\n",
    "print(\"Row indices (in hrv_train_with_labels) with outliers:\", train_outlier_idx)\n",
    "print(\"Outlier HRV_MedianNN values:\", outlier_values)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c7026677b951d4dc",
   "metadata": {},
   "source": [
    "# Visualise one outlier ECG\n",
    "\n",
    "example_outlier_row = train_outlier_idx[0]\n",
    "\n",
    "# Single row\n",
    "row = hrv_train_with_labels.loc[example_outlier_row]\n",
    "\n",
    "# Extract ECG index value\n",
    "ecg_index_values = row.filter(like=\"ecg_index\").values\n",
    "\n",
    "# Use first value\n",
    "ecg_idx = int(ecg_index_values[0])\n",
    "\n",
    "# Extract raw ECG from df\n",
    "ecg_raw = df.iloc[ecg_idx].astype(float).values\n",
    "\n",
    "# Visualise R-Peaks\n",
    "peaks_outlier, info_outlier = nk.ecg_peaks(\n",
    "    ecg_raw,\n",
    "    sampling_rate=sampling_frequency,\n",
    "    correct_artifacts=True,\n",
    "    show=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6f7a3330073a16e7",
   "metadata": {},
   "source": [
    "hrv_train_with_labels.loc[example_outlier_row]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "76b35d498eed70a6",
   "metadata": {},
   "source": [
    "#### **Outliers TEST set** done the same way as for TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "id": "d355c44c827365f6",
   "metadata": {},
   "source": [
    "# Align TEST columns to TRAIN columns\n",
    "\n",
    "# Align TEST columns to TRAIN columns (no leakage, same feature space)\n",
    "train_cols = hrv_train_clean.columns  # already cleaned on TRAIN\n",
    "shared_cols = [c for c in train_cols if c in hrv_test_clean.columns]\n",
    "\n",
    "hrv_test_aligned = hrv_test_clean[shared_cols].copy()\n",
    "\n",
    "# Merge TEST HRV with labels\n",
    "hrv_test_with_labels = pd.merge(\n",
    "    hrv_test_aligned,\n",
    "    df_labels[[\"label\", \"classification\"]],\n",
    "    left_on=\"ecg_index\",\n",
    "    right_index=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "97a81e7e91f3cb56",
   "metadata": {},
   "source": [
    "# Same IQR bounds as on hrv_train\n",
    "\n",
    "Q1 = hrv_train_clean[\"HRV_MedianNN\"].quantile(0.25)\n",
    "Q3 = hrv_train_clean[\"HRV_MedianNN\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "hrv_test_clean = hrv_test_with_labels[\n",
    "    (hrv_test_with_labels[\"HRV_MedianNN\"] >= lower_bound) &\n",
    "    (hrv_test_with_labels[\"HRV_MedianNN\"] <= upper_bound)\n",
    "    ].copy()\n",
    "\n",
    "print(\"hrv_test shape:\", hrv_test_clean.shape)\n",
    "print(\"hrv_test_with_labels shape:\", hrv_test_with_labels.shape)\n",
    "print(\"hrv_test_clean shape:\", hrv_test_clean.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e8f18f565bb691b7",
   "metadata": {},
   "source": [
    "## Distribution TRAIN + TEST | Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "id": "95a28d78ac47363a",
   "metadata": {},
   "source": [
    "print(hrv_train_clean.columns[:5])\n",
    "print(hrv_test_clean.columns[:5])\n",
    "print(hrv_test_clean[[\"HRV_MedianNN\", \"classification\"]].head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c25fde41c2e9aa6",
   "metadata": {},
   "source": [
    "for feat in [\"HRV_MedianNN\", \"HRV_SDNN\"]:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.kdeplot(\n",
    "        data=hrv_train_clean, x=feat, label=\"Train\", fill=True, common_norm=False\n",
    "    )\n",
    "    sns.kdeplot(\n",
    "        data=hrv_test_clean, x=feat, label=\"Test\", fill=True, common_norm=False, color=\"orange\"\n",
    "    )\n",
    "    plt.title(f\"{feat}: Train vs Test\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f5ba9ff7868a4a8b",
   "metadata": {},
   "source": [
    "### Outlier Handling TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2ff30ad886cc05",
   "metadata": {},
   "source": [
    "#### Winsorising outliers"
   ]
  },
  {
   "cell_type": "code",
   "id": "5e5ef13507fe5518",
   "metadata": {},
   "source": [
    "Q1 = hrv_train_with_labels[\"HRV_MedianNN\"].quantile(0.25)\n",
    "Q3 = hrv_train_with_labels[\"HRV_MedianNN\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_clip = Q1 - 1.5 * IQR\n",
    "upper_clip = Q3 + 1.5 * IQR\n",
    "\n",
    "hrv_train_winsor = hrv_train_with_labels.copy()\n",
    "hrv_train_winsor[\"HRV_MedianNN_winsor\"] = hrv_train_with_labels[\"HRV_MedianNN\"].clip(\n",
    "    lower=lower_clip, upper=upper_clip\n",
    ")\n",
    "\n",
    "print(\"Shape after winsorizing (same as original):\", hrv_train_winsor.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5784e0c94e4a6076",
   "metadata": {},
   "source": [
    "### Outlier Handling Comparison"
   ]
  },
  {
   "cell_type": "code",
   "id": "7e270ce4d4d3105d",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(hrv_train_with_labels[\"HRV_MedianNN\"], kde=True, color=\"red\", label=\"Original\")\n",
    "sns.histplot(hrv_train_winsor[\"HRV_MedianNN_winsor\"], kde=True, color=\"green\", label=\"Winsorized\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Outlier Handling Comparison\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8811d9407209d33f",
   "metadata": {},
   "source": [
    "# Final Preprocessing: Building ML Matrices (X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "id": "808717ddc32befd1",
   "metadata": {},
   "source": [
    "# Select HRV feature columns only\n",
    "feature_cols = [col for col in hrv_train_with_labels.columns if col.startswith(\"HRV_\")]\n",
    "\n",
    "# TRAIN data\n",
    "x_train = hrv_train_with_labels[feature_cols].copy()\n",
    "y_train = hrv_train_with_labels[\"classification\"].copy()\n",
    "\n",
    "# TEST data\n",
    "x_test = hrv_test_clean[feature_cols].copy()\n",
    "y_test = hrv_test_clean[\"classification\"].copy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4205f6e90e740053",
   "metadata": {},
   "source": [
    "# Replace +/- inf with NaN in both TRAIN and TEST\n",
    "for df_ in (x_train, x_test):\n",
    "    df_.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Drop columns that are all-NaN (if any)\n",
    "all_nan_cols = x_train.columns[x_train.isna().all()]\n",
    "if len(all_nan_cols) > 0:\n",
    "    print(\"Dropping all-NaN columns before imputation:\", list(all_nan_cols))\n",
    "    x_train.drop(columns=all_nan_cols, inplace=True)\n",
    "    x_test.drop(columns=all_nan_cols, inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f416990de42cd4a3",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "code",
   "id": "331970276ce7a777",
   "metadata": {},
   "source": [
    "# Median imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "# X_train: fit_transform\n",
    "X_train_imputed = imputer.fit_transform(x_train)\n",
    "\n",
    "# X_test: only transform (so test set remains untouched)\n",
    "X_test_imputed = imputer.transform(x_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "15abcdeb289f5573",
   "metadata": {},
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "id": "c5d065ed84b20c34",
   "metadata": {},
   "source": [
    "#Temporarily convert to DataFrame to calculate Skewness easily\n",
    "temp_df = pd.DataFrame(X_train_imputed, columns=feature_cols)\n",
    "skewness = temp_df.skew().sort_values(ascending=False)\n",
    "\n",
    "#Identify skewed columns (Threshold > 1.0)\n",
    "skewed_cols = skewness[abs(skewness) > 1.0].index.tolist()\n",
    "\n",
    "#Apply Log Transform directly to the NumPy arrays\n",
    "for col_name in skewed_cols:\n",
    "    # Find the column index (integer position)\n",
    "    col_idx = feature_cols.index(col_name)\n",
    "\n",
    "    # Check for negative values (Log crashes on negatives)\n",
    "    # We find the global minimum for this column across Train and Test\n",
    "    min_val = min(X_train_imputed[:, col_idx].min(), X_test_imputed[:, col_idx].min())\n",
    "\n",
    "    shift = 0\n",
    "    if min_val < 0:\n",
    "        # If negatives exist, calculate a shift to make the minimum 0\n",
    "        shift = abs(min_val)\n",
    "\n",
    "    # Apply transformation in-place: Log(x + shift + 1)\n",
    "    X_train_imputed[:, col_idx] = np.log1p(X_train_imputed[:, col_idx] + shift)\n",
    "    X_test_imputed[:, col_idx] = np.log1p(X_test_imputed[:, col_idx] + shift)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "51d3ff7d06fd93cc",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "id": "b86af43c55a5ba1d",
   "metadata": {},
   "source": [
    "scaler = RobustScaler()\n",
    "\n",
    "# X_train: fit_transform\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "\n",
    "# X_test: only transform (so test set remains untouched)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Convert back to df with column names\n",
    "x_train = pd.DataFrame(X_train_scaled, columns=feature_cols)\n",
    "x_test = pd.DataFrame(X_test_scaled, columns=feature_cols)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ec382f92da049c00",
   "metadata": {},
   "source": [
    "### **Sanity checks**"
   ]
  },
  {
   "cell_type": "code",
   "id": "26f29c228cb64bf1",
   "metadata": {},
   "source": [
    "# Median X_train\n",
    "print(\"Median of scaled features (should be ~0):\")\n",
    "print(x_train.median().round(3))\n",
    "\n",
    "# IQR X_train\n",
    "print(\"\\nIQR of scaled features (should be ~1):\")\n",
    "print((x_train.quantile(0.75) - x_train.quantile(0.25)).round(3))\n",
    "\n",
    "#Checking skewness of the datasets\n",
    "skewness_train = x_train.skew().sort_values(ascending=False)\n",
    "skewness_test = x_train.skew().sort_values(ascending=False)\n",
    "# Filter for highly skewed columns (absolute skew > 1.0)\n",
    "high_skew_cols_train = skewness_train[abs(skewness_train) > 1.0]\n",
    "high_skew_cols_test = skewness_test[abs(skewness_test) > 1.0]\n",
    "\n",
    "print(len(high_skew_cols_train))\n",
    "print(len(high_skew_cols_test))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2a36ba7605b95a6a",
   "metadata": {},
   "source": [
    "# Final ML datasets (X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "id": "92cc335720ca9288",
   "metadata": {},
   "source": [
    "print(\"Train size:\", len(train_idx))\n",
    "print(\"Test size:\", len(test_idx))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ec10523a1e004990",
   "metadata": {},
   "source": [
    "if True:\n",
    "    # Feature matrices (winsorised > imputation > scaling)\n",
    "    x_train = X_train_scaled\n",
    "    x_test = X_test_scaled\n",
    "\n",
    "    # Target vectors (created earlier from HRV + labels AF(0/1))\n",
    "    y_train = hrv_train_with_labels[\"classification\"].copy()\n",
    "    y_test = hrv_test_clean[\"classification\"].copy()\n",
    "\n",
    "    print(\"Final X_train shape:\", x_train.shape)\n",
    "    print(\"Final X_test shape:\", x_test.shape)\n",
    "    print(\"Final y_train shape:\", y_train.shape)\n",
    "    print(\"Final y_test shape:\", y_test.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "24142419a84363d0",
   "metadata": {},
   "source": [
    "# Machine Learning Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d1464a95c41b61",
   "metadata": {},
   "source": [
    "## Safety check"
   ]
  },
  {
   "cell_type": "code",
   "id": "fd31ca358371c93e",
   "metadata": {},
   "source": [
    "assert len(x_train) == len(y_train), \"Misaligned TRAIN matrix and labels!\"\n",
    "assert len(x_test) == len(y_test), \"Misaligned TEST matrix and labels!\"\n",
    "\n",
    "assert not np.isnan(x_train).any(), \"NaNs detected in X_train!\"\n",
    "assert not np.isnan(x_test).any(), \"NaNs detected in X_test!\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "12e32109e5ee457",
   "metadata": {},
   "source": [
    "## Comparison framework"
   ]
  },
  {
   "cell_type": "code",
   "id": "37efe7aec3749c6",
   "metadata": {},
   "source": [
    "resultsTable = pd.DataFrame(columns=['Model', 'Accuracy', 'F1 Score', 'Precision', 'Recall', 'ROC', 'ROC_AUC', 'cm'])\n",
    "\n",
    "def modelResults(model, accuracy, f1, precision, recall, roc_auc, roc_cur, cm):\n",
    "    print(\n",
    "        f\"Model {model} evaluated. \\nAccuracy: {accuracy} \\nF1 Score: {f1} \\nPrecision: {precision} \\nRecall: {recall} \\nROC AUC: {roc_auc}\")\n",
    "    resultsTable.loc[len(resultsTable)] = [model, accuracy, f1, precision, recall, roc_cur, roc_auc, cm]\n",
    "    resultsTable.to_csv(\"data/trainingResults.csv\", index=False, mode=\"a\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T19:11:35.179763Z",
     "start_time": "2025-11-26T19:11:35.174374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hyperParameterResultsTable = pd.DataFrame(columns=['Model', 'Accuracy', 'F1 Score', 'Precision', 'Recall', 'ROC', 'ROC_AUC', 'cm'])\n",
    "\n",
    "def hyperParameterResults(model, accuracy, f1, precision, recall, roc_auc, roc_cur, cm):\n",
    "    print(\n",
    "        f\"Model {model} evaluated. \\nAccuracy: {accuracy} \\nF1 Score: {f1} \\nPrecision: {precision} \\nRecall: {recall} \\nROC AUC: {roc_auc}\")\n",
    "    hyperParameterResultsTable.loc[len(resultsTable)] = [model, accuracy, f1, precision, recall, roc_cur, roc_auc, cm]\n",
    "    hyperParameterResultsTable.to_csv(\"data/hyperParameterResults.csv\", index=False, mode=\"a\")\n"
   ],
   "id": "624ad9d92ed62fa8",
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "id": "4886d8bf749e585f",
   "metadata": {},
   "source": [
    "print(\n",
    "    f\"X train length: {len(x_train)}\\n X test length: {len(x_test)} \\n Y train length: {len(y_train)}\\n Y test length: {len(y_test)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "50d9a88ad21d69c1",
   "metadata": {},
   "source": [
    "# Machine Learning Training"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "#Going back to basics, the currently used x_train and x_test gave ValueErrors as negative values for Log\n",
    "\n",
    "raw_cols = [c for c in hrv_train_with_labels.columns if c.startswith(\"HRV_\")]\n",
    "raw_train = hrv_train_with_labels[raw_cols].copy()\n",
    "raw_test = hrv_test_clean[raw_cols].copy()\n",
    "\n",
    "raw_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "raw_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "imputer_eng = SimpleImputer(strategy=\"median\")\n",
    "raw_train_imp = pd.DataFrame(imputer_eng.fit_transform(raw_train), columns=raw_cols)\n",
    "raw_test_imp = pd.DataFrame(imputer_eng.transform(raw_test), columns=raw_cols)\n",
    "\n",
    "skewness = raw_train_imp.skew().sort_values(ascending=False)\n",
    "skewed_cols = skewness[abs(skewness) > 1.0].index.tolist()\n",
    "\n",
    "new_features_train = pd.DataFrame(index=raw_train_imp.index)\n",
    "new_features_test = pd.DataFrame(index=raw_test_imp.index)\n",
    "\n",
    "#1. Log Transforms\n",
    "for col in skewed_cols:\n",
    "    # +1e-6 avoids log(0)\n",
    "    new_features_train[f'Log_{col}'] = np.log(raw_train_imp[col] + 1e-6)\n",
    "    new_features_test[f'Log_{col}'] = np.log(raw_test_imp[col] + 1e-6)\n",
    "\n",
    "#2. 2. Coefficient of Variation (CV) computation:\n",
    "if 'HRV_SDNN' in raw_train_imp.columns and 'HRV_MeanNN' in raw_train_imp.columns:\n",
    "    new_features_train['CV_SDNN'] = raw_train_imp['HRV_SDNN'] / (raw_train_imp['HRV_MeanNN'] + 1e-6)\n",
    "    new_features_test['CV_SDNN'] = raw_test_imp['HRV_SDNN'] / (raw_test_imp['HRV_MeanNN'] + 1e-6)\n",
    "\n",
    "# 3. Chaos Index (Amplifies the \"irregularly irregular\" signal specific to AF.):\n",
    "entropy_col = 'HRV_ApEn' if 'HRV_ApEn' in raw_train_imp.columns else 'HRV_SampEn'\n",
    "if 'HRV_RMSSD' in raw_train_imp.columns and entropy_col in raw_train_imp.columns:\n",
    "    new_features_train['Chaos_Index'] = raw_train_imp['HRV_RMSSD'] * raw_train_imp[entropy_col]\n",
    "    new_features_test['Chaos_Index'] = raw_test_imp['HRV_RMSSD'] * raw_test_imp[entropy_col]\n",
    "\n",
    "new_features_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "new_features_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "imputer_new = SimpleImputer(strategy=\"median\")\n",
    "new_train_clean = pd.DataFrame(imputer_new.fit_transform(new_features_train), columns=new_features_train.columns)\n",
    "new_test_clean = pd.DataFrame(imputer_new.transform(new_features_test), columns=new_features_test.columns)\n",
    "\n",
    "scaler_eng = RobustScaler()\n",
    "new_train_scaled = pd.DataFrame(scaler_eng.fit_transform(new_train_clean), columns=new_features_train.columns)\n",
    "new_test_scaled = pd.DataFrame(scaler_eng.transform(new_test_clean), columns=new_features_test.columns)\n",
    "\n",
    "if not isinstance(x_train, pd.DataFrame):\n",
    "    x_train = pd.DataFrame(x_train, columns=feature_cols)\n",
    "if not isinstance(x_test, pd.DataFrame):\n",
    "    x_test = pd.DataFrame(x_test, columns=feature_cols)\n",
    "\n",
    "x_train_added = pd.concat([x_train, new_train_scaled], axis=1)\n",
    "x_test_added = pd.concat([x_test, new_test_scaled], axis=1)"
   ],
   "id": "466a673194d59ec6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "97a1a9262acb8046",
   "metadata": {},
   "source": [
    "## Soft voting classifier"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Change hyperparameters of LR",
   "id": "c008c0783e8b0213"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Change hyperparameters of RF",
   "id": "d4cc5ed502e93729"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Change hyperparameters of KNN",
   "id": "4cbfb0da51854b39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Change hyperparameters of ADA",
   "id": "7d3bf0dfe2f2afb0"
  },
  {
   "cell_type": "markdown",
   "id": "68136b826462600d",
   "metadata": {},
   "source": [
    "## Best Voting Classifier Search"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "\n",
    "# Define the pool of base classifiers with various hyperparameters\n",
    "classifiers_pool = [\n",
    "    ('LR_balanced', LogisticRegression(multi_class='auto', max_iter=1000, class_weight='balanced', random_state=3003)),\n",
    "    ('LR_default', LogisticRegression(multi_class='auto', max_iter=1000, random_state=3003)),\n",
    "    ('RF_100', RandomForestClassifier(n_estimators=100, random_state=3003)),\n",
    "    ('RF_200', RandomForestClassifier(n_estimators=200, random_state=3003)),\n",
    "    ('RF_300', RandomForestClassifier(n_estimators=200, random_state=3003)),\n",
    "    ('KNN_5', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('KNN_7', KNeighborsClassifier(n_neighbors=7)),\n",
    "    ('GBC_100', GradientBoostingClassifier(n_estimators=100, random_state=3003)),\n",
    "    ('GBC_200', GradientBoostingClassifier(n_estimators=200, random_state=3003)),\n",
    "    ('Ada_50', AdaBoostClassifier(n_estimators=50, random_state=3003)),\n",
    "    ('Ada_100', AdaBoostClassifier(n_estimators=100, random_state=3003))\n",
    "]\n",
    "\n",
    "best_f1_found = -1\n",
    "best_voting_model = None\n",
    "best_ensemble_name = \"\"\n",
    "\n",
    "print(\"Searching for best Voting Classifier configuration (optimizing for F1 Score)...\")\n",
    "\n",
    "# Iterate through all possible combinations of length 2 to 4 (limiting to 4 to avoid too long runtime)\n",
    "for r in range(2, 5):\n",
    "    for ensemble in itertools.combinations(classifiers_pool, r):\n",
    "        # Create a name for this combination\n",
    "        names = [name for name, _ in ensemble]\n",
    "        ensemble_name = f\"BestVote ({'+'.join(names)})\"\n",
    "\n",
    "        # Create the voting classifier\n",
    "        # Using soft voting as these models support probability estimates\n",
    "        voter = VotingClassifier(estimators=list(ensemble), voting='soft', n_jobs=-1)\n",
    "\n",
    "        # Train\n",
    "        voter.fit(x_train_added, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = voter.predict(x_test_added)\n",
    "        y_pred_proba = voter.predict_proba(x_test_added)[:, 1]\n",
    "\n",
    "        # Evaluate\n",
    "        current_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        roc_cur = roc_curve(y_test, y_pred_proba)\n",
    "        cm = confusion_matrix(y_true=y_test, y_pred=y_pred, normalize='true')\n",
    "        modelResults(ensemble, accuracy, current_f1, precision, recall, roc_auc, roc_cur, cm)\n",
    "\n",
    "\n",
    "\n",
    "        # print(f\"Tested {ensemble_name}: F1 Score = {current_f1:.4f}\")\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        roc_cur = roc_curve(y_test, y_pred_proba)\n",
    "        cm = confusion_matrix(y_true=y_test, y_pred=y_pred, normalize='true')\n",
    "\n",
    "        modelResults(ensemble_name, accuracy, current_f1, precision, recall, roc_auc, roc_cur, cm)\n",
    "\n",
    "        if current_f1 > best_f1_found:\n",
    "            best_f1_found = current_f1\n",
    "            best_voting_model = voter\n",
    "            best_ensemble_name = ensemble_name\n",
    "\n",
    "print(f\"\\nWinner configuration: {best_ensemble_name} with F1 Score: {best_f1_found:.4f}\")\n",
    "\n",
    "# Log the best result to the global resultsTable\n",
    "if best_voting_model:\n",
    "    y_pred = best_voting_model.predict(x_test)\n",
    "    y_pred_proba = best_voting_model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    roc_cur = roc_curve(y_test, y_pred_proba)\n",
    "    cm = confusion_matrix(y_true=y_test, y_pred=y_pred, normalize='true')\n",
    "\n",
    "    # Plot matrix for the winner\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_voting_model.classes_)\n",
    "    disp.plot()\n",
    "    plt.title(f\"Best Found Ensemble: {best_ensemble_name}\")\n",
    "    plt.show()"
   ],
   "id": "33ccb24c52904e91",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e2078b02730ef972",
   "metadata": {},
   "source": [
    "# Model evaluation\n",
    "## Quick conclusion"
   ]
  },
  {
   "cell_type": "code",
   "id": "a74e735f580bc275",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T19:06:07.124500Z",
     "start_time": "2025-11-26T19:06:07.119588Z"
    }
   },
   "source": [
    "original_size = resultsTable.shape[0]\n",
    "resultsTable = resultsTable.drop_duplicates(subset=['Model', 'Accuracy', 'F1 Score', 'Precision', 'Recall', 'ROC_AUC'])\n",
    "print(f\"Dropped {original_size - resultsTable.shape[0]} duplicate rows\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 duplicate rows\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "id": "22fb0d0456fb3e19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T19:07:46.730622Z",
     "start_time": "2025-11-26T19:07:46.725685Z"
    }
   },
   "source": [
    "resultsTable"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Model, Accuracy, F1 Score, Precision, Recall, ROC, ROC_AUC, cm]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>ROC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "id": "c38fea59ebb09553",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T19:06:10.783626Z",
     "start_time": "2025-11-26T19:06:10.781144Z"
    }
   },
   "source": [
    "top_models = resultsTable.sort_values(by='F1 Score', ascending=False).head(5)\n",
    "\n",
    "print(\"Top 5 models based on F1 score:\")\n",
    "for i, (_, row) in enumerate(top_models.iterrows(), 1):\n",
    "    print(f\"{i}. {row['Model']} with an F1 score of {row['F1 Score']:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 models based on F1 score:\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "id": "e8e285a0ca7eadd2",
   "metadata": {},
   "source": [
    "## Graphs of numerical metrics\n",
    "### Logarithmic scale"
   ]
  },
  {
   "cell_type": "code",
   "id": "fb7c2b82a89e3bf8",
   "metadata": {},
   "source": [
    "if True:\n",
    "    numeric_metrics = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'ROC_AUC']\n",
    "\n",
    "    model_labels = [str(model).split('(')[0] for model in resultsTable['Model']]\n",
    "\n",
    "    fig, axes = plt.subplots(len(numeric_metrics), 1, figsize=(10, len(numeric_metrics) * 8))\n",
    "\n",
    "    for i, col in enumerate(numeric_metrics):\n",
    "        bars = axes[i].bar(range(len(resultsTable)), resultsTable[col])\n",
    "        axes[i].set_xticks(range(len(resultsTable)))\n",
    "        axes[i].set_xticklabels(model_labels, rotation=45, ha='right')\n",
    "        axes[i].set_ylabel(col)\n",
    "        axes[i].set_title(f'{col} by Model')\n",
    "        axes[i].set_yscale('log')\n",
    "        axes[i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "        for j, bar in enumerate(bars):\n",
    "            height = bar.get_height()\n",
    "            axes[i].text(bar.get_x() + bar.get_width() / 2., height,\n",
    "                         f'{resultsTable[col].iloc[j]:.3f}',\n",
    "                         ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1738534b97511a26",
   "metadata": {},
   "source": [
    "numeric_metrics = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'ROC_AUC']\n",
    "\n",
    "model_labels = [str(model).split('(')[0] for model in resultsTable['Model']]\n",
    "\n",
    "fig, axes = plt.subplots(len(numeric_metrics), 1, figsize=(10, len(numeric_metrics) * 8))\n",
    "\n",
    "for i, col in enumerate(numeric_metrics):\n",
    "    bars = axes[i].bar(range(len(resultsTable)), resultsTable[col])\n",
    "    axes[i].set_xticks(range(len(resultsTable)))\n",
    "    axes[i].set_xticklabels(model_labels, rotation=45, ha='right')\n",
    "    axes[i].set_ylabel(col)\n",
    "    axes[i].set_title(f'{col} by Model')\n",
    "    axes[i].set_ylim(top=1)\n",
    "    axes[i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "    for j, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        axes[i].text(bar.get_x() + bar.get_width() / 2., height,\n",
    "                     f'{resultsTable[col].iloc[j]:.3f}',\n",
    "                     ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2f15fb5d2e241296",
   "metadata": {},
   "source": [
    "## ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "id": "fd4a03846706aed",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for idx, row in resultsTable.iterrows():\n",
    "    model_name = str(row['Model']).split('(')[0]\n",
    "    fpr, tpr, thresholds = row['ROC']\n",
    "    roc_auc = row['ROC_AUC']\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{model_name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier (AUC = 0.500)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curves - Model Comparison', fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=12)\n",
    "plt.grid(alpha=1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data-Witches",
   "language": "python",
   "name": "data-witches"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
